{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://www.timzhangyuxuan.com/static/images/project_DCGAN/structure.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The generator and discriminator are trying to optimize the opposite thing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator Cost(Binary CrossEntropy)\n",
    "\n",
    "\\begin{equation*}\n",
    "J= -[t logy +(1-t)log(1-y)]\n",
    "\\end{equation*}\n",
    "\n",
    "- t = 1 mena real and t = 0 mena fake\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- z is latent vector G(z) is generator output function\n",
    "\n",
    "\\begin{equation*}\n",
    "J^{(D)}= -[logD(x) +log(1-D(G(z)))]  \n",
    "\\end{equation*}\n",
    "\\begin{equation*}\n",
    "J^D(θ^D, θ^G) = − \\frac{1}{2} \\mathbb{E}_{x \\sim p_{data}} log D(x) − \\frac{1}{2} \\mathbb{E}_{z} log  (1 − D (G(z)))\n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator Cost\n",
    "\n",
    "- try to maximize the discriminator's cost\n",
    "\n",
    "\n",
    "\\begin{equation*}\n",
    "J^{G}= -J^{D}\n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimax\n",
    "\n",
    "- zero-sum game are called minimax game\n",
    "\n",
    "\n",
    "\\begin{equation*}\n",
    "\\theta_{G}^{*} = argmin_{\\theta_{G}}max_{\\theta_{D}}- J^{D}\n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://jhui.github.io/assets/gm/gmc.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$log(1-D(G(z)))]  $ , if $D(G(z)$ is 1, slope is $-\\infty$  the gradient of J diminishes for MiniMax game and Maximum likelihood game. The generator cannot learn.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator\n",
    "\n",
    "![](https://jhui.github.io/assets/gm/gm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Transpose convolution\n",
    "\n",
    "![](https://jhui.github.io/assets/gm/transpose.gif)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fractional strided convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- if we use stride = 1/2, result is 2x original\n",
    "\n",
    "- in TF, convolution filter is specified like  \n",
    "(filter height, filter width, # feature map in, # feature map out)\n",
    "- Strides   \n",
    "(1, vertical stride, horizontal stride,1)\n",
    "\n",
    "- here  \n",
    "(filter height, filter width, # feature map out,# feature map in)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The input z to the model is a 100-Dimensional vector (100 random numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch Normalization\n",
    "- with batch norm, instead of manually normalizing data first, we do a normalization at every layer of the neural net\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$X_{B}$ = next batch of data  \n",
    "$\\mu_{B}$ = mean($X_{B}$)  \n",
    "$\\sigma$ = std($X_{B}$)  \n",
    "$Y_{B}$ = ($X_{B}-\\mu_{B}$)\\$\\sigma_{B}$   \n",
    "\n",
    "$Y_{B}$ = ($X_{B}-\\mu_{B}$)\\ $\\sqrt{\\sigma_{B}^2+\\epsilon}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - MNIST dataset\n",
    "\n",
    "```python\n",
    "class DCGAN:\n",
    "  def __init__(self, img_length, num_colors, d_sizes, g_sizes):\n",
    "\n",
    "    # save for later\n",
    "    self.img_length = img_length # 28\n",
    "    self.num_colors = num_colors # 1\n",
    "    self.latent_dims = g_sizes['z'] # 100\n",
    "\n",
    "    '(N,28,28,1)'\n",
    "    # define the input data\n",
    "    self.X = tf.placeholder(\n",
    "      tf.float32,\n",
    "      shape=(None, img_length, img_length, num_colors),\n",
    "      name='X'\n",
    "    )\n",
    "    '(N,100)'\n",
    "    self.Z = tf.placeholder(\n",
    "      tf.float32,\n",
    "      shape=(None, self.latent_dims),\n",
    "      name='Z'\n",
    "    )\n",
    "\n",
    "    self.batch_sz = tf.placeholder(tf.int32, shape=(), name='batch_sz')\n",
    "    \n",
    "    # build the discriminator\n",
    "    logits = self.build_discriminator(self.X, d_sizes)\n",
    "\n",
    "    # build generator\n",
    "    self.sample_images = self.build_generator(self.Z, g_sizes)\n",
    "    ...\n",
    "    \n",
    "    def build_generator(self, Z, g_sizes):\n",
    "        with tf.variable_scope(\"generator\") as scope:\n",
    "\n",
    "            'dims = [28,14,7]' #stride is 2  \n",
    "            # determine the size of the data at each step\n",
    "            dims = [self.img_length]\n",
    "            dim = self.img_length\n",
    "            for _, _, stride, _ in reversed(g_sizes['conv_layers']):\n",
    "                dim = int(np.ceil(float(dim) / stride))\n",
    "                dims.append(dim)\n",
    "            # note: dims is actually backwards\n",
    "            # the first layer of the generator is actually last\n",
    "            # so let's reverse it\n",
    "            dims = list(reversed(dims))\n",
    "            print(\"dims:\", dims)\n",
    "            self.g_dims = dims\n",
    "            'dims: [7, 14, 28]'\n",
    "            \n",
    "            '(N,100)->(N,1024)->(N,7,7,128)->(N,14,14,128)->(N,28,28,1)'\n",
    "            'dense_layer shape g_denselayer_0 : (# latent input,#feature map out)'\n",
    "            '(100,1024)'\n",
    "            # dense layers\n",
    "            mi = self.latent_dims\n",
    "            self.g_denselayers = []\n",
    "            count = 0\n",
    "            for mo, apply_batch_norm in g_sizes['dense_layers']:\n",
    "                name = \"g_denselayer_%s\" % count\n",
    "                count += 1\n",
    "\n",
    "                layer = DenseLayer(name, mi, mo, apply_batch_norm)\n",
    "                self.g_denselayers.append(layer)\n",
    "                mi = mo\n",
    "            \n",
    "            'mo = 128*7*7'\n",
    "            'mi = 1024, mo= 128*7*7(6272)'\n",
    "            # final dense layer\n",
    "            mo = g_sizes['projection'] * dims[0] * dims[0]\n",
    "            name = \"g_denselayer_%s\" % count\n",
    "            layer = DenseLayer(name, mi, mo, not g_sizes['bn_after_project'])\n",
    "            self.g_denselayers.append(layer)    \n",
    "            \n",
    "            'mi is 128'\n",
    "            # fs-conv layers\n",
    "            mi = g_sizes['projection']\n",
    "            self.g_convlayers = []\n",
    "            \n",
    "            'num_relus is 1'\n",
    "            'activation_functions = [tf.nn.relu, tf.sigmoid]\n",
    "            # output may use tanh or sigmoid\n",
    "            num_relus = len(g_sizes['conv_layers']) - 1\n",
    "            activation_functions = [tf.nn.relu]*num_relus + [g_sizes['output_activation']]\n",
    "            \n",
    "            'output shape 0 (#batch num, 14,14,128)'\n",
    "            'output shape 1 (#batch num, 28,28,1)'\n",
    "            'mi: 128 mo: 128 outp shape: [<tf.Tensor 'batch_sz:0' shape=() dtype=int32>, 14, 14, 128]'\n",
    "            'mi: 128 mo: 1 outp shape: [<tf.Tensor 'batch_sz:0' shape=() dtype=int32>, 28, 28, 1]'\n",
    "            for i in range(len(g_sizes['conv_layers'])):\n",
    "                name = \"fs_convlayer_%s\" % i\n",
    "                mo, filtersz, stride, apply_batch_norm = g_sizes['conv_layers'][i]\n",
    "                f = activation_functions[i]\n",
    "                output_shape = [self.batch_sz, dims[i+1], dims[i+1], mo]\n",
    "                print(\"mi:\", mi, \"mo:\", mo, \"outp shape:\", output_shape)\n",
    "                layer = FractionallyStridedConvLayer(\n",
    "                  name, mi, mo, output_shape, apply_batch_norm, filtersz, stride, f\n",
    "                )\n",
    "                self.g_convlayers.append(layer)\n",
    "                mi = mo\n",
    "            # get the output\n",
    "            self.g_sizes = g_sizes\n",
    "            return self.g_forward(Z)\n",
    "        \n",
    "    def g_forward(self, Z, reuse=None, is_training=True):\n",
    "        # dense layers\n",
    "        output = Z\n",
    "        for layer in self.g_denselayers:\n",
    "            output = layer.forward(output, reuse, is_training)\n",
    "\n",
    "        # project and reshape\n",
    "        output = tf.reshape(\n",
    "          output,\n",
    "          [-1, self.g_dims[0], self.g_dims[0], self.g_sizes['projection']],\n",
    "        )\n",
    "\n",
    "        # apply batch norm\n",
    "        if self.g_sizes['bn_after_project']:\n",
    "            output = tf.contrib.layers.batch_norm(\n",
    "                output,\n",
    "                decay=0.9, \n",
    "                updates_collections=None,\n",
    "                epsilon=1e-5,\n",
    "                scale=True,\n",
    "                is_training=is_training,\n",
    "                reuse=reuse,\n",
    "                scope='bn_after_project'\n",
    "              )\n",
    "        \n",
    "        # pass through fs-conv layers\n",
    "        for layer in self.g_convlayers:\n",
    "            output = layer.forward(output, reuse, is_training)\n",
    "\n",
    "        return output            \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator\n",
    "\n",
    "![](https://image.slidesharecdn.com/unsupervisedlearningrepresenationwithdcgan-170608192900/95/unsupervised-learning-represenation-with-dcgan-14-638.jpg?cb=1496950222)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```txt\n",
    "ConvLayer Tensor(\"discriminator/Maximum:0\", shape=(?, 14, 14, 2), dtype=float32)\n",
    "ConvLayer Tensor(\"discriminator/Maximum_1:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
    "ConvLayer flatten Tensor(\"discriminator/Flatten/flatten/Reshape:0\", shape=(?, 3136), dtype=float32)\n",
    "Tensor(\"discriminator/add:0\", shape=(?, 1024), dtype=float32)\n",
    "denseLayer Tensor(\"discriminator/Maximum_2:0\", shape=(?, 1024), dtype=float32)\n",
    "Tensor(\"discriminator/add_1:0\", shape=(?, 1), dtype=float32)\n",
    "denseLayer logits Tensor(\"discriminator/add_1:0\", shape=(?, 1), dtype=float32)\n",
    "```\n",
    "\n",
    "```python\n",
    "# for mnist\n",
    "d_sizes = {\n",
    "'conv_layers': [(2, 5, 2, False), (64, 5, 2, True)],'mo, filtersz, stride, apply_batch_norm'\n",
    "'dense_layers': [(1024, True)],'mo, apply_batch_norm'\n",
    "}\n",
    "\n",
    "# build the discriminator\n",
    "logits = self.build_discriminator(self.X, d_sizes)\n",
    "\n",
    "def build_discriminator(self, X, d_sizes):\n",
    "    with tf.variable_scope(\"discriminator\") as scope:\n",
    "\n",
    "        '(N,28,28,1) ->(N,14,14,2):stride(2)->(N,7,7,64):stride(2)->flatten(N,3136)'\n",
    "        # build conv layers\n",
    "        self.d_convlayers = []\n",
    "        mi = self.num_colors # 1\n",
    "        dim = self.img_length # 28\n",
    "        count = 0\n",
    "        \n",
    "        for mo, filtersz, stride, apply_batch_norm in d_sizes['conv_layers']:\n",
    "            # make up a name - used for get_variable\n",
    "            name = \"convlayer_%s\" % count\n",
    "            count += 1\n",
    "\n",
    "            layer = ConvLayer(name, mi, mo, apply_batch_norm, filtersz, stride, lrelu)\n",
    "            self.d_convlayers.append(layer)\n",
    "            mi = mo\n",
    "            print(\"dim:\", dim)\n",
    "            dim = int(np.ceil(float(dim) / stride))\n",
    "        \n",
    "        'mi = mi * dim * dim= 64*7*7=3136 - > dense layer (N,1024)'\n",
    "        mi = mi * dim * dim\n",
    "        # build dense layers\n",
    "        self.d_denselayers = []\n",
    "        for mo, apply_batch_norm in d_sizes['dense_layers']:\n",
    "            name = \"denselayer_%s\" % count\n",
    "            count += 1\n",
    "\n",
    "            layer = DenseLayer(name, mi, mo, apply_batch_norm, lrelu)\n",
    "            mi = mo\n",
    "            self.d_denselayers.append(layer)\n",
    "        \n",
    "        '->(N,1)'\n",
    "        # final logistic layer\n",
    "        name = \"denselayer_%s\" % count\n",
    "        self.d_finallayer = DenseLayer(name, mi, 1, False, lambda x: x)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# build the discriminator\n",
    "logits = self.build_discriminator(self.X, d_sizes)\n",
    "\n",
    "# build generator\n",
    "self.sample_images = self.build_generator(self.Z, g_sizes)\n",
    "\n",
    "# get sample logits\n",
    "with tf.variable_scope(\"discriminator\") as scope:\n",
    "  scope.reuse_variables()\n",
    "  sample_logits = self.d_forward(self.sample_images, True)\n",
    "\n",
    "# get sample images for test time (batch norm is different)\n",
    "with tf.variable_scope(\"generator\") as scope:\n",
    "  scope.reuse_variables()\n",
    "  self.sample_images_test = self.g_forward(\n",
    "    self.Z, reuse=True, is_training=False\n",
    "  )\n",
    "\n",
    "    \n",
    "# build costs\n",
    "self.d_cost_real = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "  logits=logits,\n",
    "  labels=tf.ones_like(logits)\n",
    ")\n",
    "self.d_cost_fake = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "  logits=sample_logits,\n",
    "  labels=tf.zeros_like(sample_logits)\n",
    ")    \n",
    "\n",
    "self.d_cost = tf.reduce_mean(self.d_cost_real) + tf.reduce_mean(self.d_cost_fake)\n",
    "\n",
    "self.g_cost = tf.reduce_mean(\n",
    "  tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "    logits=sample_logits,\n",
    "    labels=tf.ones_like(sample_logits)\n",
    "  )\n",
    ")\n",
    "\n",
    "real_predictions = tf.cast(logits > 0, tf.float32)\n",
    "fake_predictions = tf.cast(sample_logits < 0, tf.float32)\n",
    "num_predictions = 2.0*BATCH_SIZE\n",
    "num_correct = tf.reduce_sum(real_predictions) + tf.reduce_sum(fake_predictions)\n",
    "self.d_accuracy = num_correct / num_predictions\n",
    "\n",
    "\n",
    "# optimizers\n",
    "self.d_params = [t for t in tf.trainable_variables() if t.name.startswith('d')]#discriminator scope\n",
    "self.g_params = [t for t in tf.trainable_variables() if t.name.startswith('g')]#generator scope\n",
    "\n",
    "self.d_train_op = tf.train.AdamOptimizer(\n",
    "  LEARNING_RATE, beta1=BETA1\n",
    ").minimize(\n",
    "  self.d_cost, var_list=self.d_params\n",
    ")\n",
    "self.g_train_op = tf.train.AdamOptimizer(\n",
    "  LEARNING_RATE, beta1=BETA1\n",
    ").minimize(\n",
    "  self.g_cost, var_list=self.g_params\n",
    ")\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- reference  \n",
    "[Generative-adversarial-models](https://jhui.github.io/2017/03/05/Generative-adversarial-models/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./opensrc/machine_learning_examples-master/unsupervised_class3\") \n",
    "\n",
    "import util\n",
    "import os\n",
    "import util\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "# X, Y = util.get_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looks like you haven't downloaded the data or it's not in the right spot.\n",
      "Please get train.csv from https://www.kaggle.com/c/digit-recognizer\n",
      "and place it in the large_files folder.\n",
      "Reading in and transforming data...\n",
      "dim: 28\n",
      "dim: 14\n",
      "ConvLayer Tensor(\"discriminator/Maximum:0\", shape=(?, 14, 14, 2), dtype=float32)\n",
      "ConvLayer Tensor(\"discriminator/Maximum_1:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
      "ConvLayer flatten Tensor(\"discriminator/Flatten/flatten/Reshape:0\", shape=(?, 3136), dtype=float32)\n",
      "Tensor(\"discriminator/add:0\", shape=(?, 1024), dtype=float32)\n",
      "denseLayer Tensor(\"discriminator/Maximum_2:0\", shape=(?, 1024), dtype=float32)\n",
      "Tensor(\"discriminator/add_1:0\", shape=(?, 1), dtype=float32)\n",
      "denseLayer logits Tensor(\"discriminator/add_1:0\", shape=(?, 1), dtype=float32)\n",
      "dims: [7, 14, 28]\n",
      "mi: 128 mo: 128 outp shape: [<tf.Tensor 'batch_sz:0' shape=() dtype=int32>, 14, 14, 128]\n",
      "mi: 128 mo: 1 outp shape: [<tf.Tensor 'batch_sz:0' shape=() dtype=int32>, 28, 28, 1]\n",
      "Tensor(\"generator/add:0\", shape=(?, 1024), dtype=float32)\n",
      "Tensor(\"generator/add_1:0\", shape=(?, 6272), dtype=float32)\n",
      "ConvLayer Tensor(\"discriminator_1/Maximum:0\", shape=(?, 14, 14, 2), dtype=float32)\n",
      "ConvLayer Tensor(\"discriminator_1/Maximum_1:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
      "ConvLayer flatten Tensor(\"discriminator_1/Flatten/flatten/Reshape:0\", shape=(?, 3136), dtype=float32)\n",
      "Tensor(\"discriminator_1/add:0\", shape=(?, 1024), dtype=float32)\n",
      "denseLayer Tensor(\"discriminator_1/Maximum_2:0\", shape=(?, 1024), dtype=float32)\n",
      "Tensor(\"discriminator_1/add_1:0\", shape=(?, 1), dtype=float32)\n",
      "denseLayer logits Tensor(\"discriminator_1/add_1:0\", shape=(?, 1), dtype=float32)\n",
      "Tensor(\"generator_1/add:0\", shape=(?, 1024), dtype=float32)\n",
      "Tensor(\"generator_1/add_1:0\", shape=(?, 6272), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import dcgan_tf as dcgan\n",
    "\n",
    "X, Y = util.get_mnist()\n",
    "X = X.reshape(len(X), 28, 28, 1)\n",
    "dim = X.shape[1]\n",
    "colors = X.shape[-1]\n",
    "\n",
    "# for mnist\n",
    "d_sizes = {\n",
    "'conv_layers': [(2, 5, 2, False), (64, 5, 2, True)],\n",
    "'dense_layers': [(1024, True)],\n",
    "}\n",
    "g_sizes = {\n",
    "'z': 100,\n",
    "'projection': 128,\n",
    "'bn_after_project': False,\n",
    "'conv_layers': [(128, 5, 2, True), (colors, 5, 2, False)],\n",
    "'dense_layers': [(1024, True)],\n",
    "'output_activation': tf.sigmoid,\n",
    "}\n",
    "\n",
    "\n",
    "# setup gan\n",
    "# note: assume square images, so only need 1 dim\n",
    "gan = dcgan.DCGAN(dim, colors, d_sizes, g_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(g_sizes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
