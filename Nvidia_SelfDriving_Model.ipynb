{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nvidia Self -Driving Netork Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imgaug import augmenters as iaa\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import ntpath\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NVIDIA CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This is an Implmentation of Nvidia's End to End Steer control as follows\n",
    "![](https://devblogs.nvidia.com/wp-content/uploads/2016/08/training-624x291.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Below is network architecture\n",
    "![](https://devblogs.nvidia.com/wp-content/uploads/2016/08/cnn-architecture-624x890.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nvidia_model():\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(24, 5, 5, subsample=(2, 2), input_shape=(66, 200, 3), activation='elu'))\n",
    "    model.add(Convolution2D(36, 5, 5, subsample=(2, 2), activation='elu'))\n",
    "    model.add(Convolution2D(48, 5, 5, subsample=(2, 2), activation='elu'))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='elu'))\n",
    "\n",
    "    model.add(Convolution2D(64, 3, 3, activation='elu'))\n",
    "    #   model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(100, activation = 'elu'))\n",
    "    #   model.add(Dropout(0.5))\n",
    "    model.add(Dense(50, activation = 'elu'))\n",
    "    #   model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation = 'elu'))\n",
    "    #   model.add(Dropout(0.5))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    optimizer = Adam(lr=1e-3)\n",
    "    model.compile(loss='mse', optimizer=optimizer)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/home9second/.virtualenvs/deeplearning/lib/python3.5/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (5, 5), strides=(2, 2), activation=\"elu\", input_shape=(66, 200, ...)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/home9second/.virtualenvs/deeplearning/lib/python3.5/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(36, (5, 5), activation=\"elu\", strides=(2, 2))`\n",
      "  after removing the cwd from sys.path.\n",
      "/home/home9second/.virtualenvs/deeplearning/lib/python3.5/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(48, (5, 5), activation=\"elu\", strides=(2, 2))`\n",
      "  \"\"\"\n",
      "/home/home9second/.virtualenvs/deeplearning/lib/python3.5/site-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"elu\")`\n",
      "  \n",
      "/home/home9second/.virtualenvs/deeplearning/lib/python3.5/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"elu\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_11 (Conv2D)           (None, 31, 98, 24)        1824      \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 14, 47, 36)        21636     \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 5, 22, 48)         43248     \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 3, 20, 64)         27712     \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 1, 18, 64)         36928     \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               115300    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 252,219\n",
      "Trainable params: 252,219\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = nvidia_model()\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Augmentation\n",
    "\n",
    "After selecting the final set of frames, we augment the data by adding artificial shifts and rotations to teach the network how to recover from a poor position or orientation. The magnitude of these perturbations is chosen randomly from a normal distribution. The distribution has zero mean, and the standard deviation is twice the standard deviation that we measured with human drivers. Artificially augmenting the data does add undesirable artifacts as the magnitude increases (as mentioned previously)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale up to 1.3\n",
    "def zoom(image):\n",
    "    zoom = iaa.Affine(scale=(1, 1.3))\n",
    "    image = zoom.augment_image(image)\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pan(image):\n",
    "    pan = iaa.Affine(translate_percent= {\"x\" : (-0.1, 0.1), \"y\": (-0.1, 0.1)})\n",
    "    image = pan.augment_image(image)\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_random_brightness(image):\n",
    "    brightness = iaa.Multiply((0.2, 1.2))\n",
    "    image = brightness.augment_image(image)\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_random_flip(image, steering_angle):\n",
    "    image = cv2.flip(image,1)\n",
    "    steering_angle = -steering_angle\n",
    "    return image, steering_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def img_preprocess(img):\n",
    "    img = img[60:135,:,:]\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "    img = cv2.GaussianBlur(img,  (3, 3), 0)\n",
    "    img = cv2.resize(img, (200, 66))\n",
    "    img = img/255\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(image_paths, steering_ang, batch_size, istraining):\n",
    "    while True:\n",
    "        batch_img = []\n",
    "        batch_steering = []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            random_index = random.randint(0, len(image_paths) - 1)\n",
    "\n",
    "            if istraining:\n",
    "                im, steering = random_augment(image_paths[random_index], steering_ang[random_index])\n",
    "\n",
    "            else:\n",
    "                im = mpimg.imread(image_paths[random_index])\n",
    "                steering = steering_ang[random_index]\n",
    "\n",
    "            im = img_preprocess(im)\n",
    "            batch_img.append(im)\n",
    "            batch_steering.append(steering)\n",
    "            \n",
    "        yield (np.asarray(batch_img), np.asarray(batch_steering)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(batch_generator(X_train, y_train, 100, 1),\n",
    "                                  steps_per_epoch=300, \n",
    "                                  epochs=10,\n",
    "                                  validation_data=batch_generator(X_valid, y_valid, 100, 0),\n",
    "                                  validation_steps=200,\n",
    "                                  verbose=1,\n",
    "                                  shuffle = 1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
