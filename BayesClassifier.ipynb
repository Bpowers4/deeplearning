{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://deeplearningcourses.com/c/deep-learning-gans-and-variational-autoencoders\n",
    "# https://www.udemy.com/deep-learning-gans-and-variational-autoencoders\n",
    "from __future__ import print_function, division\n",
    "from builtins import range, input\n",
    "# Note: you may need to update your version of future\n",
    "# sudo pip install -U future\n",
    "\n",
    "import util\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multivariate_normal as mvn\n",
    "\n",
    "\n",
    "def clamp_sample(x):\n",
    "  x = np.minimum(x, 1)\n",
    "  x = np.maximum(x, 0)\n",
    "  return x\n",
    "\n",
    "\n",
    "class BayesClassifier:\n",
    "  def fit(self, X, Y):\n",
    "    # assume classes are numbered 0...K-1\n",
    "    self.K = len(set(Y))\n",
    "\n",
    "    self.gaussians = []\n",
    "    self.p_y = np.zeros(self.K)\n",
    "    for k in range(self.K):\n",
    "      Xk = X[Y == k]\n",
    "      self.p_y[k] = len(Xk)\n",
    "      mean = Xk.mean(axis=0)\n",
    "      cov = np.cov(Xk.T)\n",
    "      g = {'m': mean, 'c': cov}\n",
    "      self.gaussians.append(g)\n",
    "    # normalize p(y)\n",
    "    self.p_y /= self.p_y.sum()\n",
    "\n",
    "  def sample_given_y(self, y):\n",
    "    g = self.gaussians[y]\n",
    "    return clamp_sample( mvn.rvs(mean=g['m'], cov=g['c']) )\n",
    "\n",
    "  def sample(self):\n",
    "    y = np.random.choice(self.K, p=self.p_y)\n",
    "    return clamp_sample( self.sample_given_y(y) )\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  X, Y = util.get_mnist()\n",
    "  clf = BayesClassifier()\n",
    "  clf.fit(X, Y)\n",
    "\n",
    "  for k in range(clf.K):\n",
    "    # show one sample for each class\n",
    "    # also show the mean image learned\n",
    "\n",
    "    sample = clf.sample_given_y(k).reshape(28, 28)\n",
    "    mean = clf.gaussians[k]['m'].reshape(28, 28)\n",
    "\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(sample, cmap='gray')\n",
    "    plt.title(\"Sample\")\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(mean, cmap='gray')\n",
    "    plt.title(\"Mean\")\n",
    "    plt.show()\n",
    "\n",
    "  # generate a random sample\n",
    "  sample = clf.sample().reshape(28, 28)\n",
    "  plt.imshow(sample, cmap='gray')\n",
    "  plt.title(\"Random Sample from Random Class\")\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[bayes-classifier-and-naive-bayes-tutorial-using](https://lazyprogrammer.me/bayes-classifier-and-naive-bayes-tutorial-using/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "c^* = argmax_{c}{ P(c | x) } =argmax_{c}{ \\frac{ P(x | c)P(c) }{ P(x) } }\n",
    "$\n",
    "\n",
    "You will notice that P(x) is constant for all values of c in P(c|x).\n",
    "\n",
    "So when I take the argmax over P(x|c)P(c)P(x)\n",
    "I can ignore P(x)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this information, we can simplify our problem so that, in order to choose “which digit” given an image, all we need to do is calculate this argmax (notice P(x) is removed):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "c^* = argmax_{c}{ P(x | c)P(c) }\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A reasonable first-guess for modeling continuous data is the multivariate Gaussian or the multivariate Normal.\n",
    "\n",
    "$\n",
    "P(x | c) = \\frac{1}{\\sqrt{ (2\\pi)^D |\\Sigma| }} exp\\left({ -\\frac{1}{2}(x – \\mu)^T \\Sigma^{-1} (x – \\mu) }\\right)\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The log-likelihood can be represented as:\n",
    "\n",
    "$\n",
    "logP(x | c) = -\\frac{D}{2}ln(2\\pi) – \\frac{1}{2}ln|\\Sigma| – \\frac{1}{2}(x – \\mu)^T \\Sigma^{-1} (x – \\mu)\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Earlier, we wanted the argmax over P(x|c)P(c). Since log(AB)=log(A)+log(B), then using log probabilities, we can choose the digit class using:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "c^* = argmax_{c} {\\left( logP(x | c) + logP(c) \\right)}\n",
    "$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
