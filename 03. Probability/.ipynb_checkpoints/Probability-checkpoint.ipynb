{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expectation(Random Variable)\n",
    "\n",
    "The expectation of a random variable is a number that attempts to capture the center of that random variable's distribution. It can be interpreted as the long-run average of many independent samples from the given distribution. More precisely, it is defined as the probability-weighted sum of all possible values in the random variable's support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{E}[X] = \\sum_{x \\in \\mathcal{X}}xP(x)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variance\n",
    "Whereas expectation provides a measure of centrality, the variance of a random variable quantifies the spread of that random variable's distribution. The variance is the average value of the squared difference between the random variable and its expectation\n",
    "\n",
    "$$\n",
    "\\text{Var}(X) = \\text{E}[(X - \\text{E}[X])^2] \\\\\n",
    "\\text{Var}(X) = \\text{E}(X^2) - \\text{E(X)}^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Example, compute the variance of a die roll, a uniform random variable over the sample space  $\\Omega$ = {1,2,3,4,5,6}\n",
    "\n",
    "$$\n",
    "Var(X) = E[X- E(X)]^2\\\\\n",
    "       = E(X^2) - E(X)^2 \\\\\n",
    "       = (\\sum_{k=1}^{6}k^2 \\cdot \\frac{1}{6}) - (3.5)^2 \\\\\n",
    "       = \\frac{1}{6}\\cdot(1+4+9+16+25+36) - 3.5^2\\\\\n",
    "       = \\frac{1}{6}\\cdot91 - 3.5^2\\\\\n",
    "       \\approx 2.92\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discrete Random Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[probability-distributions](https://seeing-theory.brown.edu/probability-distributions/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A discrete random variable has a finite or countable number of possible values\n",
    "- if X is a discrete random vatiable, then these exists unique nonnegative function f(x), and F(x), such that the following are true\n",
    "\n",
    "$$\n",
    "P(X = x) = f(x)\\\\\n",
    "P(X < x) = F(x)\n",
    "$$\n",
    "\n",
    "- f(x) is the probability mass function \n",
    "- F(x) is the cumulative distribution fuction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli distribution \n",
    "\n",
    "$$\n",
    "f(x;p) = \\begin{cases} p & \\text{if } x = 1 \\\\ 1-p & \\text{if } x = 0 \\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A binomial random variable\n",
    "is the sum of n independent Bernoulli random variables with parameter p. It is frequently used to model the number of successes in a specified number of identical binary experiments, such as the number of heads in five coin tosses.\n",
    "\n",
    "$$\n",
    "f(x; n,p) = \\binom{n}{x}p^{x}(1-p)^{n-x}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Poisson random variable\n",
    "counts the number of events occurring in a fixed interval of time or space, given that these events occur with an average rate λ. This distribution has been used to model events such as meteor showers and goals in a soccer match\n",
    "\n",
    "$$\n",
    "f(x;\\lambda) = \\dfrac{\\lambda^{x}e^{-\\lambda}}{x!}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Random Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If X is a continuous random variable, then there exists unique nonnegative functions, f(x) and F(x), such that the following are true:\n",
    "$$\n",
    "P(a \\le X \\le b) = \\int_{a}^{b}f(x)dx\\\\\n",
    "P(X \\lt x) = F(x)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniform distribution\n",
    "\n",
    "$$\n",
    "f(x;a,b) = \\left\\{\\begin{array}{ll} \\dfrac{1}{b-a} \\text{ for } x \\in [a,b]\\\\ 0 \\qquad \\text{ otherwise } \\end{array}\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal (Gaussian) distribution\n",
    "\n",
    "$$\n",
    "f(x;\\mu, \\sigma^2) = \\dfrac{1}{\\sqrt{2\\pi\\sigma^{2}}} e^{-\\dfrac{(x-\\mu)^{2}}{2\\sigma^{2}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beta distribution\n",
    "The beta distribution is a general family of continuous probability distributions bound between 0 and 1. The beta distribution is frequently used as a conjugate prior distribution in Bayesian statistics  \n",
    "\n",
    "$$\n",
    "f(x;\\alpha,\\beta) = \\dfrac{\\Gamma(\\alpha + \\beta)x^{\\alpha - 1}(1-x)^{\\beta - 1}}{\\Gamma(\\alpha)\\Gamma(\\beta)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confidence Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that during the presidential election, we were interested inthe proportion p of the population that preferred Hillary Clinton toDonald Trump. It wouldn’t be feasible to call every single person inthe country and write down who they prefer. Instead, we can take abunch of samples,$X_{1}, . . . ,X_{n}$where"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "X_{i} = \\left\\{\\begin{array}{ll} 1 \\text{ if person i prefers Hillary } \\\\ 0 \\qquad \\text{ otherwise } \\end{array}\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The sample mean \n",
    "\n",
    "$$\n",
    "\\hat{X} = \\frac{1}{N}\\sum_{i=1}^{n}X_{i}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$E(\\hat{X}) = p$ each $X_{i}$ is 1 with probability p and 0 with probability 1-p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by the CLT\n",
    "$$\n",
    "\\frac{(\\hat{X} - p)}{(\\sigma/\\sqrt{N})} \\sim N(0,1)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we don't know $\\sigma$\n",
    "- But this is a valid approximation\n",
    "\n",
    "$$\n",
    "\\hat{\\sigma} = \\sqrt{\\frac{1}{N}\\sum_{i=1}^{N}(X_{i}-\\hat{X})^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "P(-1.96\\le \\frac{\\hat{X} - p}{\\hat{\\sigma}/\\sqrt{N}} \\le 1.96) = 0.95\\\\\n",
    "P(\\hat{X}-1.96\\frac{\\hat{\\sigma}}{\\sqrt{N}} \\le p \\le \\hat{X}+1.96\\frac{\\hat{\\sigma}}{\\sqrt{N}}) = 0.95\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Above formula looks like below   \n",
    "$$\n",
    "[\\hat{\\mu}+z_{left}\\frac{\\hat{\\sigma}}{\\sqrt{N}},\\hat{\\mu}+z_{right}\\frac{\\hat{\\sigma}}{\\sqrt{N}}]\\\\\n",
    "\\hat{\\sigma} = \\sqrt{\\frac{1}{N}\\sum_{i=1}^{N}(x_{i}-\\hat{\\mu})^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bernoulli Confidence Interval\n",
    "- replaced the Gaussian symbols with Bernoulli symbols\n",
    "\n",
    "var(X) = p(1-p)  \n",
    "95%CI =   \n",
    "$$\n",
    "\\approx [\\hat{p}+z_{left}\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{N}},\\hat{p}+z_{right}\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{N}}]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we suspect that the proportion ofvoters who prefer Hillary Clinton is greater than $\\frac{1}{2}$, and that we take n samples, denoted$ {X_{i}}_{i=1}^{n}$from the U.S. population. Based on thesesamples, can we support or reject our hypothesis that Hillary Clin-ton is more popular? And how confident are we in our conclusion?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The __alternative hypothesis__, denoted $H_{a}$, is a claim we would like to support. In our previous example, the alternative hypothesis was $p$ > 0.5.\n",
    "- The __null hypothesis__, denoted $H_{0}$ is the opposite of the alternative hypothesis. In this case, the null hypothesis is $p$ ≤ 0.5, i.e. that less than half of the population supports Hillary.\n",
    "- The __test statisticis__ a function of the sample observations. Based on the test statistic, we will either accept or reject the __null hypothesis__. In the previous example, the test statistic was the sample mean $\\hat{X}$. The sample mean is often the test statistic for many hypothesis tests\n",
    "- The __rejection region__ is a subset of our sample space $\\Omega$ that determines whether or not to reject the null hypothesis. If the test statistic falls in the rejection region, then we reject the null hypothesis. Otherwise, we accept it. In the presidential election example,the rejection region would be\n",
    "\n",
    "    - RR:{($x_{1},...,x_{n}$): $\\hat{X}$ > k}  \n",
    "    - This notation means we reject if ̄$\\hat{X}$ falls in the interval(k,$\\infty$),where __k__ is some number which we must determine.k is determined by the Type I error, which is defined in the next section. Once k is computed, we reject or accept the null hypothesis depending on the value of our test statistic, and our test is complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two fundamental types of errors in hypothesis testing.They are denoted Type I and II error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A Type I error is made when we reject $H_{0}$ when it is in fact true. The probability of Type I error is typically denoted as $\\alpha$. In other words, $\\alpha$ is the probability of a false positive.\n",
    "- A Type II error is made when we accept $H_{0}$ when it is in fact false. The probability of Type II error is typically denoted as $\\beta$\n",
    "- In other words, $\\beta$ is the probability of a false negative. In the context of hypothesis testing,$\\alpha$ will determine the rejection region. If we restrict the probability of a false positive to be less than 0.05, then we have  \n",
    "$P(\\hat{X} \\in RR|H_{0}) \\le 0.05$   \n",
    "- our test statistic falls in the rejection region (meaning we reject $H_{0}$), given that $H_{0}$ is true, with probability 0.05. Continuing along our example of the presidential election, the rejection region was of the form ̄$\\hat{X} \\gt$ k, and the null hypothesis was that p ≤ 0.5. Our above expression then becomes  \n",
    "$p(\\hat{X} \\gt k | p \\le 0.5) \\le$ 0.05  \n",
    "- if n > 30, we can apply the CLT to say:\n",
    "$$\n",
    "P(\\frac{\\hat{X}-p}{S/\\sqrt{n}} \\gt \\frac{k-p}{S/\\sqrt{n}} | p \\le 0.5) = P(Y \\gt \\frac{k-p}{S/\\sqrt{n}} | p \\le 0.5)\n",
    "$$\n",
    "\n",
    "- where Y is N(0,1) random variable, since p $\\le$ 0.5 implies \n",
    "$\\frac{k-p}{S/\\sqrt{n}} \\geq \\frac{k-0.5}{S/\\sqrt{n}} $  \n",
    "- hence\n",
    "$$\n",
    "P(Y \\gt \\frac{k-p}{S/\\sqrt{n}}  | p \\le 0.5) \\le P(Y \\gt \\frac{k-0.5}{S/\\sqrt{n}} )\n",
    "$$\n",
    "\n",
    "- we can loop up a z table to find $z_{0.05}$ = -1.64\n",
    "$$\n",
    "P(Y \\gt 1.64) = P(Y  \\lt -1.64) = 0.05\n",
    "$$\n",
    "\n",
    "- letting $\\frac{k-0.5}{S/\\sqrt{n}} = 1.64$, we can solve for k to determine our rejection region\n",
    "\n",
    "$$\n",
    "k = 0.5 + 1.64\\cdot \\frac{S}{\\sqrt{n}}\n",
    "$$\n",
    "\n",
    "- since our rejection region was of the form $\\hat{X}$ > k, we simply check whether $\\hat{X} \\gt 0.5 + \\frac{S}{\\sqrt{n}}$.\n",
    "- If this is true, then we reject the null, and conclude that more than half the population favors Hillary Clinton.\n",
    "- Since we set $\\alpha$ = 0.05, we are 1 - $\\alpha$ = 0.95 confident that our conclusion was correct\n",
    "\n",
    "- In the above example, we determined the rejection region by plugging in 0.5 for p, even though the null hypothesis was p ≤ 0.5. It is almost as though our null hypothesis was $H_{0}$:p=0.5 instead of $H_{0}$:p ≤ 0.5. In general, we can simplify $H_{0}$ and assume the bordercase (p=0.5 in this case) when we are determining the rejection region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1888/2017/05/11170656/3159.png)\n",
    "![](http://financetrain.com/assets/cip3.gif)\n",
    "![](https://www.researchgate.net/profile/Avijit_Hazra/publication/320742650/figure/download/tbl1/AS:669269071237158@1536577589946/Critical-z-values-used-in-the-calculation-of-confidence-intervals.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### p-value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw in the previous section, a selected $\\alpha$ determined the rejection region so that the probability of a false positive was less than $\\alpha$. Now suppose we observe some test statistic, say, the sample proportion of voters ̄$\\hat{X}$ who prefer Hillary Clinton. We then ask the following question. Given ̄$\\hat{X}$, what is the smallest value of $\\alpha$ suchthat we still reject the null hypothesis? This leads us to the following definition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The p-value, denoted p, is defined  \n",
    "p=min{$ \\alpha \\in (0, 1):\\text{Reject } H_{0} \\text{using an }\\alpha \\text{level test}$}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This definition isn’t that useful for computing p-values. In fact,there is a more intuitive way of thinking about them. Suppose we observe some sample mean $\\hat{X}_{1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now suppose we draw a new sample mean, $\\hat{X}_{2}$ The p-value is just the probability that our new sample mean is more extreme than the one we first observed, assuming the null hypothesis is true. By “extreme” we mean, more different from our null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that we sampled n people and asked which candidate they preferred. As we did before, we can represent each person as an indicator function,\n",
    "\n",
    "$$\n",
    "X_{i} = \\left\\{\\begin{array}{ll} 1 \\text{ if person i prefers Hillary } \\\\ 0 \\qquad \\text{ otherwise } \\end{array}\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Then $\\hat{X}$ is the proportion of the sample that prefers Hillary. After taking the n samples, suppose we observe that $\\hat{X}$ = 0.7. If we were to set up a hypothesis test, our hypotheses, test statistic, and rejection region would be\n",
    "\n",
    "$$\n",
    "H_{0} : q \\le 0.5 \\\\\n",
    "H_{a} : q \\gt 0.5 \\\\\n",
    "Test statistics : \\hat{X} \\\\\n",
    "RR:(x_{1},...,x_{n}): \\hat{X} \\gt k\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- where q is the true proportion of the entire U.S. population that favors Hillary. Using the intuitive definition, the p value is the probability that we observe something more extreme than 0.7. Since the null hypothesis is that q ≤ 0.5, “more extreme” in this case means, “bigger than 0.7”. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- So the p-value is the probability that, given a new sample, we observe the new $\\hat{X}$ is greater than 0.7, assuming the null, i.e. that q ≤ 0.5. Normalizing $\\hat{X}$, we have\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "P(\\hat{X} \\gt 0.7 | H_{0}) = P(\\frac{\\hat{X}-0.5}{S/\\sqrt{n}} \\gt P(\\frac{0.7-0.5}{S/\\sqrt{n}} ) \\approx P(Y \\gt \\frac{0.7-0.5}{S/\\sqrt{n}})= p(p-value)\n",
    "$$\n",
    "\n",
    "- refer below:\n",
    "    - previous example : $P(\\hat{X} \\in RR|H_{0}) \\le p-value:0.05$  \n",
    "    - $p(\\hat{X} \\gt k | p \\le 0.5) \\le$ 0.05  \n",
    "    - $P(Y \\gt \\frac{k-p}{S/\\sqrt{n}}  | p \\le 0.5) \\le P(Y \\gt \\frac{k-0.5}{S/\\sqrt{n}} )$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- where Y∼N(0, 1). We would then compute the value $z_{p}$=$\\frac{0.7−0.5}{S/√n}$by plugging in the sample standard deviation, S, and the number of samples we took, n. \n",
    "- We would then look up a z table and find the probability corresponding to $z_{p}$, denoted p (this is our p value).\n",
    "- We now claim that this p is equal to the smallest $\\alpha$ for which we reject the null hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we need to show that for any $\\alpha$ < p, we accept the null hypothesis. We also need to show that for any $\\alpha$ ≥ p, we reject the null hypothesis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Suppose $\\alpha$ <p. We need to show that the test statistic $\\hat{X}$=0.7 falls in the acceptance region determined by $\\alpha$. Using a z table, we couldfind $z_{\\alpha}$such that  \n",
    "$$\n",
    "\\alpha = P(Y \\gt z_{\\alpha}) \\approx P(\\frac{\\hat{X}- 0.5}{S/\\sqrt{n}} \\gt z_{\\alpha}|H_{0}) = P(\\hat{X} \\gt z_{\\alpha}\\cdot \\frac{S}{\\sqrt{n}}+ 0.5 | H_{0})\n",
    "$$\n",
    "\n",
    "- the rejection region is determined by \n",
    "$$\n",
    "\\hat{X} \\gt k_{\\alpha} = z_{\\alpha}\\cdot\\frac{S}{\\sqrt{n}} + 0.5\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Since $\\alpha$ < p, the corresponding $z_{p}$ such that p=P(Y>$z_{p}$) satisfies $z_{p}$<$z_{\\alpha}$. By the RHS of expression (1)\n",
    "\n",
    "$$\n",
    "p = P(Y \\gt \\frac{0.7-0.5}{S/\\sqrt{n}})\n",
    "$$\n",
    "\n",
    "- which implies $z_{p} = \\frac{0.7-0.5}{S/\\sqrt{n}} \\Rightarrow z_{p}\\cdot \\frac{S}{\\sqrt{n}}+0.5 = 0.7$. This implies that  \n",
    "\n",
    "$$\n",
    "0.7 = z_{p}\\cdot\\frac{S}{\\sqrt{n}} + 0.5 \\lt z_{\\alpha}\\cdot\\frac{S}{\\sqrt{n}}+0.5 = k_{\\alpha}\n",
    "$$\n",
    "\n",
    "- Therefore $\\hat{X}$=0.7< $k_{\\alpha}$  implies $\\hat{X}$=0.7 is in the acceptance region determined by $\\alpha$. Hence, we accept the null hypothesis for any $\\alpha$<p.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "[basic-probability](https://seeing-theory.brown.edu/doc/basic-probability.pdf)\n",
    "[probability-distributions](https://seeing-theory.brown.edu/probability-distributions/index.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
