{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Bayes Rule Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes Rule & Probability Review\n",
    "- You 've probably already seen below formula\n",
    "\n",
    "$$p(A|B) = \\frac{p(A,B)}{p(B)}$$\n",
    "\n",
    "- $p(A|B)$ - conditional\n",
    "- $p(A,B)$ - joint\n",
    "- $p(B)$ - marginal \n",
    "- This is the most basic form, but too abstract\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes Example\n",
    "\n",
    "- A = {Buy, does not buy} ,B = {USA,Candada,Mexico}\n",
    "- Suppose we want to find p(Buy?|Country)\n",
    "\n",
    "[]()|CA|US|MX|\n",
    "----|---|---|---|\n",
    "Buy = 1(did buy)|20|50|10|\n",
    "Buy = 0(did not buy)|300|500|200|\n",
    "\n",
    "- Marginal probability\n",
    "- p(country=Mexico) = 210/(210+550+320) = 0.19\n",
    "- p(country=US) = 550/(210+550+320) = 0.51\n",
    "- p(country=CA) = 320/(210+550+320) = 0.30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joint Probabilities\n",
    "- Now let's find p(Buy?,Country)\n",
    "- How many possibilities?\n",
    "- Buy?= 2 possibilities\n",
    "- Country = 3 possibilities\n",
    "- Total possibilities = 2 x 3 = 6\n",
    "- Think of it as an area or volume\n",
    "- In general, total = |RV1| x|RV2|x |RV3| x ... x|RVn|\n",
    "- Grows exponentially as we add more variables\n",
    "- Curse of dimensionality\n",
    "- is a bad thing, because as the volume grows\n",
    "- we need to do more computation\n",
    "- need more samples to get accurate estimates\n",
    "- p(Buy = 1,CA) = 20/1080(210+550+320) = 0.019\n",
    "- p(Buy = 0,CA) = 300/1080(210+550+320) = 0.28\n",
    "- p(Buy = 1,US) = 50/1080(210+550+320) = 0.046\n",
    "- p(Buy = 0,US) = 500/1080(210+550+320) = 0.46\n",
    "- p(Buy = 1,MX) = 10/1080(210+550+320) = 0.0093\n",
    "- p(Buy = 0,MX) = 200/1080(210+550+320) = 0.19\n",
    "\n",
    "- These seem a lot smaller than the marginal \n",
    "- Sum of all possible outcomes must = 1\n",
    "- If number of total possibilities grows exponentially,actual probability values will shrink exponentially\n",
    "- Another consequence of curse of dimensionality\n",
    "- Computers have finite precision-32bit float holds 32bits of info\n",
    "- can't store infinite number of values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Underflow\n",
    "- As probability -> 0, eventually computer will round down to 0\n",
    "- called the underflow problem\n",
    "- common in probability \n",
    "- log grows slowly as its argument increases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional probabilities\n",
    "\n",
    "- p(Buy = 1|CA) = 0.019/0.30 = 0.06\n",
    "- p(Buy = 0|CA) = 0.28/0.30 = 0.93\n",
    "- p(Buy = 1|US) = 0.046/0.51 = 0.09\n",
    "- p(Buy = 0|US) = 0.46/0.51 = 0.91\n",
    "- p(Buy = 1|MX) = 0.009/0.19 = 0.05\n",
    "- p(Buy = 0|MX) = 0.185/0.19 = 0.97\n",
    "\n",
    "note: some roundoff error\n",
    "- No longer sums to 1, sums to 3 why?\n",
    "- we are given country- the space of random variables is only buy/not buy\n",
    "- country is not random here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[]()|CA|US|MX|\n",
    "----|---|---|---|\n",
    "Buy = 1(did buy)|20|50|10|\n",
    "Buy = 0(did not buy)|300|500|200|\n",
    "\n",
    "- p(Buy = 1| Country = US) = p(Buy = 1,Country = US)/p(country = US)\n",
    "- = (50/1080)/[(50+500)/1080]\n",
    "- = 0.09"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similar but different problem\n",
    "\n",
    "[]()|CA|US|MX|\n",
    "----|---|---|---|\n",
    "Buy = 1(did buy)|20|50|10|\n",
    "Buy = 0(did not buy)|200|500|100|\n",
    "\n",
    "- p(Buy=1|Country=CA) = 0.1\n",
    "- p(Buy=1|Country=US) = 0.1\n",
    "- p(Buy=1|Country=MX) = 0.1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Independence\n",
    "- When 2 variables are independent, the joint becomes the multiple of the marginals, e.g. if A &B are independent:\n",
    "- p(A,B) = p(A)p(B)\n",
    "- so, if Buy & Country are independent\n",
    "- p(Buy|Country) = p(Buy,Country)/p(Country) = p(Buy)p(Country)/p(Country) = p(Buy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulating Bayes Rule\n",
    "- let's make it look more like the form we'll use in \n",
    "$$\n",
    "p(A|B) = \\frac{p(A,B)}{p(B)}\n",
    "$$\n",
    "\n",
    "- The opposite is also true:\n",
    "$$\n",
    "p(B|A) = \\frac{p(B,A)}{p(A)}\n",
    "$$\n",
    "- Since p(A,B) = p(B,A)\n",
    "$$\n",
    "p(A|B) = \\frac{p(B|A)p(A)}{p(B)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "p(B) = \\sum_{A}^{}{p(A,B)} = \\sum_{A}^{}\\frac{p(B|A)}{p(A)}\n",
    "$$\n",
    "\n",
    "- If working with continuous distributions, sum turns into integral\n",
    "\n",
    "$$\n",
    "p(A|B) = \\frac{p(B|A)p(A)}{\\int{p(B|A)p(A)dA}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Can also think of the bottom term as a normalization constant so that the distribution sums to 1\n",
    "\n",
    "\n",
    "$$\n",
    "p(A|B) \\propto p(B|A)p(A)\n",
    "$$\n",
    "\n",
    "- Many times, we just want the $\\underset{A}{\\operatorname{argmax}}p(A|B)$\n",
    "$$\n",
    "\\underset{A}{\\operatorname{argmax}}p(A|B) = \\underset{A}{\\operatorname{argmax}}p(B|A)p(A)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes for classification\n",
    "$$\n",
    "p(y|x) = \\frac{p(x|y)p(y)}{p(x)}\n",
    "$$\n",
    "\n",
    "- p(x|y) is a generative distribution - it tells us what does x look like? given the class is y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Probability Execise\n",
    "\n",
    "- We have a fair coin: p(H) = p(T)= 0.5, H= head, T= Tail\n",
    "- we plan to toss the coin 200 times in total\n",
    "- After 20 tosses, we have 15H, 5T\n",
    "- What is the total # of heads we expect to get by the end of the experiment?\n",
    "(N = 200)\n",
    "\n",
    "## Gambler's Fallacy\n",
    "- You just lost 100 times, you must have a better chance of winning next?\n",
    "- Incorrect\n",
    "- Doesn't matter how many times you have lost already, your chance of losing next are the same as they have always been\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Monty Hall Problem\n",
    "\n",
    "- Famous problem in probability, inspired by a TV game show\n",
    "- TV show was Let's make a deal, host was monty hall, hence the monty hall problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How the game works\n",
    "- you pick a door(door 1)\n",
    "- monty hall opens a door you didn't pick, reveals a goat (door 2)\n",
    "- you are given a choice: stay with door 1 or switch to door 3\n",
    "- This question might seem silly, it doesn't matter which door you choose,\n",
    "- the probability of each is 1/3 right?\n",
    "\n",
    "[answer](https://cba.snu.ac.kr/ko/sblcolumn?mode=view&bbsidx=77838)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Maximum likelihood - Mean of Gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Maximum likelihood - what does that mean?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Gaussian sample\n",
    "- Suppose we have collected one data point from a source of Gaussian distributed data,call it x\n",
    "- What is the probability density of that one data point?\n",
    "\n",
    "$$\n",
    "p(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}exp(-\\frac{1}{2}\\frac{(x-\\mu)^2}{\\sigma^2})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple sample\n",
    "- In a real experiment, we will collect multiple samples\n",
    "- Typically these samples are IID- Independent and identically distributed\n",
    "- Identically distributed - they are all Gaussian with the same mean/variance\n",
    "- Independent\n",
    "    - If I flip coin and I've gotten 10 heads so far, what's the next toss likely to be?\n",
    "    - p(T|HHHHHHHHHH) = p(T) = 0.5\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joint probability density\n",
    "- This independence means I can multiply the probability of each individual sample to get the joint probability of all the samples\n",
    "\n",
    "$$\n",
    "p(x_{1},x_{2},...,x_{N}) =\\prod_{i=1}^{N} \\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}exp(-\\frac{1}{2}\\frac{(x_{i}-\\mu)^2}{\\sigma^2})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data likelihood\n",
    "\n",
    "- we want to phrase it as probability of data given the parameter\n",
    "- p(data|parameter)\n",
    "- Parameters depend on what the model is. e.g. Gaussian, Beta, Gammma, etc\n",
    "- Gaussian has mean/variance , we will focus on mean\n",
    "\n",
    "$$\n",
    "p(x_{1},x_{2},...,x_{N}|\\mu) =\\prod_{i=1}^{N} p(x_{i}|\\mu)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum likelihood \n",
    "- How we have likelihood, how do we maxmize it?\n",
    "- what is the best setting of $\\mu$, such that the likelihood is maximized?\n",
    "- When we want to maximize a function wrt a variable, calculus provides the tools we need\n",
    "- Taking the log is useful(log-likelihood)\n",
    "- Why? Gaussian has an exponential,derivative of exponential is the same thing, so it won't be easy to solve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting rid of the exponential\n",
    "- log(exp(A)) = A\n",
    "- This is ok because log() is a monotonically increasing function\n",
    "- if $\\mu^{*}$ yields maximum P,then it also yields maximum log(P)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log-likelihood\n",
    "\n",
    "$$\n",
    "L = logp(X|\\mu) = log \\prod_{i=1}^{N} \\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}exp(-\\frac{1}{2}\\frac{(x_{i}-\\mu)^2}{\\sigma^2})\\\\\n",
    "= \\prod_{i=1}^{N} log \\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}exp(-\\frac{1}{2}\\frac{(x_{i}-\\mu)^2}{\\sigma^2}) \\\\\n",
    "= \\prod_{i=1}^{N} -\\frac{(x_{i}-\\mu)^2}{2\\sigma^2} + const\\;wrt\\; \\mu\n",
    "$$\n",
    "\n",
    "## Derivative of log-likelihood\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\mu} = \\sum_{i=1}^{N}\\frac{x_{i}-\\mu}{\\sigma^2} = 0 \\\\\n",
    "\\mu = \\frac{1}{N}\\sum_{i=1}^{N}x_{i}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
