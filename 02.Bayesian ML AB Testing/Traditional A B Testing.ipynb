{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A/B Testing Problem Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A/B Testing\n",
    "- Scenario\n",
    "- You run a Software as a Service(SaaS) startup\n",
    "- You have a landing page where you get people to sign up\n",
    "- Signup = enter email address and click signup button\n",
    "- Not everyone who visits your site will signup\n",
    "- Conversion rate = proportion of people who sign up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Suppose your lead marketer has identified problems with your landing page(not responsive,slow load time, bad copy etc)\n",
    "- They create a new,possibly better page\n",
    "- You (as a data scientist) want to measure which page is better, using data and math\n",
    "- Recall confidence interval concept\n",
    "- we know rate(page 1) = 1/10 vs rate(page 2) = 2/10 is not as good as rate(page 1) = 10/100 vs rate(page 2) = 20/100\n",
    "- How do we quantify this?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We quantify this with statistical significance testing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Significance level = $\\alpha$ (5%, 1% common)\n",
    "- Is the difference in mean height between men and women statistically siginificant at significance level $\\alpha$?\n",
    "\n",
    "$$\n",
    "\\mu_{1} = ?\\mu_{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypotheses\n",
    "- Null hypothesis(no difference):\n",
    "    - Example: no difference in height between men and women\n",
    "    - Example: no difference in effect between drug and placebo\n",
    "    - $H_{0}: \\mu_{1} = \\mu_{2}  $\n",
    "- Alternative hypothesis(one-sided test):\n",
    "    - $H_{1}: \\mu_{1} > \\mu_{2}$\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Alternative hypothesis(2-sided test):\n",
    "    - Example: test if men taller than women OR women taller than men\n",
    "    - Example: test if drug works better than placebo OR worse than placebo\n",
    "    - $H_{1}: \\mu_{1} \\neq \\mu_{2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we will do the 2-sided test($\\neq$)\n",
    "- we will show quantitatively if the 2 groups are different"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A/B testing Recipe\n",
    "- Continue our example(height of men vs women, drug vs placebo)\n",
    "- As is typical in frequentist statistics, we will assume data is Gaussian-distributed\n",
    "- We collect some data, 2 lists of heights, one for men, one for women\n",
    "- $X_{1}$= {$x_{11},x_{12},...,x_{1N}$ }\n",
    "- $X_{2}$= {$x_{21},x_{22},...,x_{2N}$ }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We create a test statistics (called __t__)\n",
    "$$\n",
    "t = \\frac{\\bar{X}_{1}- \\bar{X}_{2}}{s_{p}\\sqrt{2/N}}\\\\\n",
    "s_{p} = \\sqrt{\\frac{s_{1}^2+s_{2}^2}{2}}\n",
    "$$\n",
    "\n",
    "- $s_{p}$ = pooled std dev(use unbiased estimates for all s - divided by N-1, not N)\n",
    "- N = size of each group\n",
    "\n",
    "- Refer below sample mean,std dev\n",
    "$$\n",
    "\\hat{\\mu} = \\frac{1}{N}\\sum_{i=1}^{N}x_{i} \\\\\n",
    "\\hat{\\sigma} = \\sqrt{\\frac{1}{N}\\sum_{i=1}^{N}(x_{i}-\\hat{\\mu})^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Recall estimate of mean - it was a sum of random variables, therefore also random variables\n",
    "- t is also a function of random variables, therefore also a random variables\n",
    "- can be shown that t is t-distributed\n",
    "- we will see t-distribution and other more exotic distribution a lot when studying statistical testing + Bayesian methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-distribution\n",
    "- looks like a Gaussian with fatter tails\n",
    "\n",
    "![](https://study.com/cimages/videopreview/o84agbwoq4.jpg)\n",
    "![](https://cn.bing.com/th?id=OIP.-3zt17eY9pfOiFcewnoiEQHaFj&pid=Api&rs=1)\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/4/41/Student_t_pdf.svg/1200px-Student_t_pdf.svg.png)\n",
    "![](http://www.obg.cuhk.edu.hk/ResearchSupport/StatTools/Pics/t.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PDF\n",
    "![](https://www.thoughtco.com/thmb/gAsKXrZg1kekAQnZVxb4J94QklA=/768x0/filters:no_upscale():max_bytes(150000):strip_icc()/tdist-56b749523df78c0b135f5be6.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we won't use it directly\n",
    "- 1 parameter : $v$ = degree of freedom (df)\n",
    "- for our statistical test, $v$ = 2N -2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Statistic\n",
    "- If mean(X1) = mean(X2) -> t = 0\n",
    "    - falls in center of t-distribution\n",
    "- If mean(X1) >> mean(X2) -> t= large\n",
    "    - falls in right tail\n",
    "- If mean(X1) << mean(X2) -> t= small\n",
    "    - falls in left tail\n",
    "    \n",
    "- symmetry -> doesn't matter if we call men = 1, women = 2 or vice versa\n",
    "\n",
    "$$\n",
    "t = \\frac{\\bar{X}_{1}- \\bar{X}_{2}}{s_{p}\\sqrt{2/N}}\\\\\n",
    "s_{p} = \\sqrt{\\frac{s_{1}^2+s_{2}^2}{2}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Area under t-dtistribution\n",
    "- Use scipy.stats.t.cdf\n",
    "- If in left tail -> CDF close to 0\n",
    "- If in right tail -> CDF close to 1\n",
    "- For a significance level $\\alpha$ = 0.05, t < -2.776, or t > 2.776\n",
    "- we call that a statistically significant difference\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# p-values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A/B testing Cont\n",
    "- Previously: I showed you an algorithm to determine whether the difference between 2 groups was statistically significant or not\n",
    "- Algorithm is done, but we need some more terminology\n",
    "- In stats, we are looking for one number < significance level($\\alpha$)\n",
    "- Should be small no matter which tail end we're on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## p-value\n",
    "- What's this small number? it's called a p-value\n",
    "- Much controversy\n",
    "- People still discussing it today\n",
    "- Out goal: get to the Bayesian way of doing things\n",
    "- p-value definition\n",
    "    - the probability of obtaining a result equal to or more extreme than what was actually observed, when the null hypothesis is true\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If: average height of men == average height of women (null hypothesis)\n",
    "- Then: p-value is the probability of observing the difference we measured(or any larger difference)\n",
    "- In other words: If t $\\propto$ mean(X1) - mean(X2) is very large, p-value should be very small\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we want to keep using our significance level $\\alpha$\n",
    "- if p-value < $\\alpha$\n",
    "- difference is statistically significant\n",
    "- we reject the null hypothesis\n",
    "- otherwise:\n",
    "- we cannot reject the null hypothesis\n",
    "- this doesnot mean the null hypothesis is true, it just means we can't reject it with the data we collected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For our example, we want p-value < 5% = 0.05\n",
    "- But the answer we got before(for statistical significance) was:\n",
    "- Area < 0.025 or Area > 0.975\n",
    "- If we get Area >0.975, take 1- Area < 0.025\n",
    "- now we have a small < 0.025\n",
    "- multiply both sides by 2\n",
    "- 2 x( small number) < 0.05\n",
    "- p-value = 2 x(small number)\n",
    "- multiply by 2 only for 2-sided test\n",
    "- one sided test -> we are only checking if X1 > X2, don't multiply by 2\n",
    "- this means the one sided test has more power than the two sided test\n",
    "- it doesn't require a test statistic to be as extreme in order to be significant \n",
    "- in general\n",
    "- the more assumptions you make, the more power your test has\n",
    "- opposite also true: less assumptions, less power\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Characteristics\n",
    "- we already know if mean(X1) >> mean(X2) or vice versa, t will be larger\n",
    "- what about $s_{p}$ and N?\n",
    "- $t \\propto \\sqrt{N}/s_{p}$\n",
    "- bigger N -> bigger t (smaller p-value)\n",
    "- bigger $s_{p}$ -> smaller t (bigger p-value) \n",
    "\n",
    "$$\n",
    "t = \\frac{\\bar{X}_{1}- \\bar{X}_{2}}{s_{p}\\sqrt{2/N}}\\\\\n",
    "s_{p} = \\sqrt{\\frac{s_{1}^2+s_{2}^2}{2}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- same situation as with confidence interval\n",
    "- t grows slowly (square root) with N\n",
    "- t decreases faster (inversely proportional) with $s_{p}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## small sample sizes?\n",
    "- t depends on N - if N is small, t is smaller, p-value is bigger\n",
    "- since statistical significance is a function of N, it already takes sample size into account\n",
    "- not correct to say small value of N makes a finding false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooled standard deviation\n",
    "- recall: N is the size of each group\n",
    "- what if each group is of a different size? take a weighted combination\n",
    "\n",
    "$$\n",
    "t = \\frac{\\bar{X}_{1}- \\bar{X}_{2}}{s_{p}\\sqrt{ \\frac{1}{n_{1}}+\\frac{1}{n_{2}}  }}\\\\\n",
    "s_{p} = \\sqrt{\\frac{(n_{1}-1)s_{X_{1}}^2+ (n_{2}-1)s_{X_{2}}^2}{n_{1}+n_{2}-2} }\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another assumption\n",
    "- not obvious- we've assumed that standard deviation of both groups is the same\n",
    "- what if they're different? use welch's t-test\n",
    "- important: the steps are the same: find t -> find df -> fidn p-value\n",
    "\n",
    "$$\n",
    "t = \\frac{\\bar{X}_{1}- \\bar{X}_{2}}{s_{\\Delta}^{-} }\\\\\n",
    "s_{\\Delta}^{-} = \\sqrt{\\frac{s_{1}^2}{n_{1}}+ \\frac{s_{2}^2}{n_{2}} }\\\\\n",
    "d.f.= \\frac{(s_{1}^2/n_{1}+s_{2}^2/n_{2})^2 }{(s_{1}^2/n_{1})^2/(n_{1}-1)+ (s_{2}^2/n_{2})^2/(n_{2}-1) }\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Assumptions\n",
    "- we assumed data was gaussian\n",
    "- we will see what test goes with click data later\n",
    "- what if we don't want to assume a distribution?\n",
    "- use nonparametric tests/distribution-free tests\n",
    "- some popular ones are\n",
    "    - kolmogorov-Smirnov test\n",
    "    - Kruskal-Wallis test\n",
    "    - Mann-Whitney U test\n",
    "- API is the same\n",
    "- less assumptions-> less power -> need more extreme difference for statistically significant p-value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-sided vs 2 sided\n",
    "- we did not make the 1 sided assumption\n",
    "- effect of 1 sided test on p-value: it's easier to show significance because we don't multiply area by 2\n",
    "- sometimes you don't want to do 1 sided test\n",
    "- Drug testing- you want to test if drug is better, you also want to test if drug is worse\n",
    "- But if you have an effective drug, and you want to test if a new drug is better, you can use a 1 sided test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "- generate test statistics, from that we know its distribution\n",
    "- look to see if it's at the extreme values of the distribution(statistical significance)\n",
    "- if statistically significant, reject the null hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# generate data\n",
    "N = 10\n",
    "a = np.random.randn(N) + 2 # mean 2, variance 1\n",
    "b = np.random.randn(N) # mean 0, variance 1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "a,b\n",
    "\n",
    "(array([0.47644157, 2.65279007, 0.66894388, 1.8490248 , 1.60699778,\n",
    "        3.02461137, 1.78354336, 0.17284328, 2.68667113, 1.66448736]),\n",
    " array([ 0.78296108, -0.14376871, -0.87388677, -0.63003727,  1.1729029 ,\n",
    "         0.02082976, -0.5373537 , -0.56871037,  0.10464732,  0.47919825]))\n",
    "```         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "#ddof : int, optional\n",
    "#“Delta Degrees of Freedom”: the divisor used in the calculation is N - ddof, where N represents the number of # elements. By default ddof is zero.\n",
    "# roll your own t-test:\n",
    "var_a = a.var(ddof=1) # unbiased estimator, divide by N-1 instead of N\n",
    "var_b = b.var(ddof=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "var_a,var_b\n",
    "(0.9500324342271126, 0.4466096488668789)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$$\n",
    "t = \\frac{\\bar{X}_{1}- \\bar{X}_{2}}{s_{p}\\sqrt{2/N}}\\\\\n",
    "s_{p} = \\sqrt{\\frac{s_{1}^2+s_{2}^2}{2}}\n",
    "$$\n",
    "```python\n",
    "s = np.sqrt( (var_a + var_b) / 2 ) # balanced standard deviation\n",
    "t = (a.mean() - b.mean()) / (s * np.sqrt(2.0/N)) # t-statistic\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "df = 2*N - 2 # degrees of freedom\n",
    "p = 1 - stats.t.cdf(np.abs(t), df=df) # one-sided test p-value\n",
    "print(\"t:\\t\", t, \"p:\\t\", 2*p) # two-sided test p-value\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# built-in t-test:\n",
    "t2, p2 = stats.ttest_ind(a, b)\n",
    "print(\"t2:\\t\", t2, \"p2:\\t\", p2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- stats.ttest_int \n",
    "- We can use this test, if we observe two independent samples from the same or different population, e.g. exam scores of boys and girls or of two ethnic groups. The test measures whether the average (expected) value differs significantly across samples. If we observe a large p-value, for example larger than 0.05 or 0.1, then we cannot reject the null hypothesis of identical average scores. If the p-value is smaller than the threshold, e.g. 1%, 5% or 10%, then we reject the null hypothesis of equal averages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# t-test Exercise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- advertisement_click.csv\n",
    "```python\n",
    "advertisement_id,action\n",
    "B,1\n",
    "B,1\n",
    "A,0\n",
    "B,0\n",
    "A,1\n",
    "A,0\n",
    "B,0\n",
    "```\n",
    "- you should check how many distinct advertisements there are(to decide whether or not to use the Bonferroni correction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What to do\n",
    "- use the t-test to determine if one advertisement is better(in a statistically significant sense) than another\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key point\n",
    "- It doesn't matter where the data came from\n",
    "- e.g. it could be news article headlines\n",
    "- what would we do?\n",
    "- simply replace the header~ new_article_id,action\n",
    "- all data is the same\n",
    "    - different landing page/website designs/logos/\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do I collect this data?\n",
    "- That's a question only you can anwser\n",
    "- e.g if you work at a company and your data is stored on Hadoop, then you'd write a script to get the data off Hadoop(or run your analysis on those files directly)\n",
    "- MySQLdb\n",
    "- SaaS and CSV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# get data\n",
    "df = pd.read_csv('advertisement_clicks.csv')\n",
    "a = df[df['advertisement_id'] == 'A']\n",
    "b = df[df['advertisement_id'] == 'B']\n",
    "a = a['action']\n",
    "b = b['action']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# built-in t-test:\n",
    "t, p = stats.ttest_ind(a, b)\n",
    "print(\"t:\\t\", t, \"p:\\t\", p)\n",
    "\n",
    "# welch's t-test:\n",
    "t, p = stats.ttest_ind(a, b, equal_var=False)\n",
    "print(\"Welch's t-test:\")\n",
    "print(\"t:\\t\", t, \"p:\\t\", p)\n",
    "\n",
    "a.mean: 0.304\n",
    "b.mean: 0.372\n",
    "t:\t -3.2211732138019786 p:\t 0.0012971905467125246\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "t = \\frac{\\bar{X}_{1}- \\bar{X}_{2}}{s_{\\Delta}^{-} }\\\\\n",
    "s_{\\Delta}^{-} = \\sqrt{\\frac{s_{1}^2}{n_{1}}+ \\frac{s_{2}^2}{n_{2}} }\\\\\n",
    "d.f.= \\frac{(s_{1}^2/n_{1}+s_{2}^2/n_{2})^2 }{(s_{1}^2/n_{1})^2/(n_{1}-1)+ (s_{2}^2/n_{2})^2/(n_{2}-1) }\n",
    "$$\n",
    "\n",
    "```python\n",
    "# welch's t-test manual:\n",
    "\n",
    "N1 = len(a)\n",
    "s1_sq = a.var()\n",
    "N2 = len(b)\n",
    "s2_sq = b.var()\n",
    "t = (a.mean() - b.mean()) / np.sqrt(s1_sq / N1 + s2_sq / N2)\n",
    "\n",
    "nu1 = N1 - 1\n",
    "nu2 = N2 - 1\n",
    "df = (s1_sq / N1 + s2_sq / N2)**2 / ( (s1_sq*s1_sq) / (N1*N1 * nu1) + (s2_sq*s2_sq) / (N2*N2 * nu2) )\n",
    "p = (1 - stats.t.cdf(np.abs(t), df=df))*2\n",
    "print(\"Manual Welch t-test\")\n",
    "print(\"t:\\t\", t, \"p:\\t\", p)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [How to Code the Student’s t-Test from Scratch in Python](https://machinelearningmastery.com/how-to-code-the-students-t-test-from-scratch-in-python/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "t = observed difference between sample means / standard error of the difference between the means\n",
    "or t = (mean(X1) - mean(X2)) / sed\n",
    "\n",
    "sed = sqrt(se1^2 + se2^2)\n",
    " \t\n",
    "se = std / sqrt(n)\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# calculate means\n",
    "mean1, mean2 = mean(data1), mean(data2)\n",
    "\n",
    "# calculate sample standard deviations\n",
    "std1, std2 = std(data1, ddof=1), std(data2, ddof=1)\n",
    "\n",
    "# calculate standard errors\n",
    "n1, n2 = len(data1), len(data2)\n",
    "se1, se2 = std1/sqrt(n1), std2/sqrt(n2)\n",
    "\n",
    "or\n",
    "#Alternately, we can use the sem() SciPy function to calculate the standard error directly\n",
    "# calculate standard errors\n",
    "se1, se2 = sem(data1), sem(data2) \n",
    "\n",
    "# standard error on the difference between the samples\n",
    "sed = sqrt(se1**2.0 + se2**2.0)\n",
    "\n",
    "# calculate the t statistic\n",
    "t_stat = (mean1 - mean2) / sed\n",
    "\n",
    "```\n",
    "__The number of degrees of freedom for the test is calculated as the sum of the observations in both samples, minus two__\n",
    "```python\n",
    "# degrees of freedom\n",
    "df = n1 + n2 - 2\n",
    "```\n",
    "\n",
    "__The critical value can be calculated using the percent point function (PPF) for a given significance level, such as 0.05 (95% confidence)__\n",
    "```python\n",
    "# calculate the critical value\n",
    "from scipy import stats\n",
    "alpha = 0.05\n",
    "cv = stats.t.ppf(1.0 - alpha, df)\n",
    "```\n",
    "\n",
    "__The p-value can be calculated using the cumulative distribution function on the t-distribution, again in SciPy__\n",
    "```python\n",
    "# calculate the p-value\n",
    "p = (1 - stats.t.cdf(abs(t_stat), df)) * 2\n",
    "```\n",
    "\n",
    "__Here, we assume a two-tailed distribution, where the rejection of the null hypothesis could be interpreted as the first mean is either smaller or larger than the second mean__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# t-test for independent samples\n",
    "from math import sqrt\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from numpy import mean\n",
    "from scipy.stats import sem\n",
    "from scipy.stats import t\n",
    "\n",
    "# function for calculating the t-test for two independent samples\n",
    "def independent_ttest(data1, data2, alpha):\n",
    "\t# calculate means\n",
    "\tmean1, mean2 = mean(data1), mean(data2)\n",
    "\t# calculate standard errors\n",
    "\tse1, se2 = sem(data1), sem(data2)\n",
    "\t# standard error on the difference between the samples\n",
    "\tsed = sqrt(se1**2.0 + se2**2.0)\n",
    "\t# calculate the t statistic\n",
    "\tt_stat = (mean1 - mean2) / sed\n",
    "\t# degrees of freedom\n",
    "\tdf = len(data1) + len(data2) - 2\n",
    "\t# calculate the critical value\n",
    "\tcv = t.ppf(1.0 - alpha, df)\n",
    "\t# calculate the p-value\n",
    "\tp = (1.0 - t.cdf(abs(t_stat), df)) * 2.0\n",
    "\t# return everything\n",
    "\treturn t_stat, df, cv, p\n",
    "\n",
    "# seed the random number generator\n",
    "seed(1)\n",
    "# generate two independent samples\n",
    "data1 = 5 * randn(100) + 50\n",
    "data2 = 5 * randn(100) + 51\n",
    "# calculate the t test\n",
    "alpha = 0.05\n",
    "t_stat, df, cv, p = independent_ttest(data1, data2, alpha)\n",
    "print('t=%.3f, df=%d, cv=%.3f, p=%.3f' % (t_stat, df, cv, p))\n",
    "# interpret via critical value\n",
    "if abs(t_stat) <= cv:\n",
    "\tprint('Accept null hypothesis that the means are equal.')\n",
    "else:\n",
    "\tprint('Reject the null hypothesis that the means are equal.')\n",
    "# interpret via p-value\n",
    "if p > alpha:\n",
    "\tprint('Accept null hypothesis that the means are equal.')\n",
    "else:\n",
    "\tprint('Reject the null hypothesis that the means are equal.')\n",
    "t=-2.262, df=198, cv=1.653, p=0.025\n",
    "Reject the null hypothesis that the means are equal.\n",
    "Reject the null hypothesis that the means are equal.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [sample-one-tailed-t-test-with-numpy-scipy](https://stackoverflow.com/questions/15984221/how-to-perform-two-sample-one-tailed-t-test-with-numpy-scipy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "First let's formulate our investigative question properly. The data we are investigating is\n",
    "\n",
    "A = np.array([0.19826790, 1.36836629, 1.37950911, 1.46951540, 1.48197798, 0.07532846])\n",
    "B = np.array([0.6383447, 0.5271385, 1.7721380, 1.7817880])\n",
    "\n",
    "with the sample means\n",
    "\n",
    "A.mean() = 0.99549419\n",
    "B.mean() = 1.1798523\n",
    "\n",
    "I assume that since the mean of B is obviously greater than the mean of A, you would like to check if this result is statistically significant.\n",
    "\n",
    "So we have the Null Hypothesis\n",
    "\n",
    "H0: A >= B\n",
    "\n",
    "that we would like to reject in favor of the Alternative Hypothesis\n",
    "\n",
    "H1: B > A\n",
    "\n",
    "Now when you call scipy.stats.ttest_ind(x, y), this makes a Hypothesis Test on the value of x.mean()-y.mean(), which means that in order to get positive values throughout the calculation (which simplifies all considerations) we have to call\n",
    "\n",
    "stats.ttest_ind(B,A)\n",
    "\n",
    "instead of stats.ttest_ind(B,A). We get as an answer\n",
    "\n",
    "    t-value = 0.42210654140239207\n",
    "    p-value = 0.68406235191764142\n",
    "\n",
    "and since according to the documentation this is the output for a two-tailed t-test we must divide the p by 2 for our one-tailed test. So depending on the Significance Level alpha you have chosen you need\n",
    "\n",
    "p/2 < alpha\n",
    "\n",
    "in order to reject the Null Hypothesis H0. For alpha=0.05 this is clearly not the case so you cannot reject H0.\n",
    "\n",
    "An alternative way to decide if you reject H0 without having to do any algebra on t or p is by looking at the t-value and comparing it with the critical t-value t_crit at the desired level of confidence (e.g. 95%) for the number of degrees of freedom df that applies to your problem. Since we have\n",
    "\n",
    "df = sample_size_1 + sample_size_2 - 2 = 8\n",
    "\n",
    "we get from a statistical table like this one that\n",
    "\n",
    "t_crit(df=8, confidence_level=95%) = 1.860\n",
    "\n",
    "We clearly have\n",
    "\n",
    "t < t_crit\n",
    "\n",
    "so we obtain again the same result, namely that we cannot reject H0.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A/B test for Click-Through Rates(Chi-Square Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for Click-Through Rates\n",
    "- you know when test, let's do another one\n",
    "- This works for click through rates(not Gaussian but Bernoulli)\n",
    "- works for any categorical variable where we count things\n",
    "\n",
    "|[]()|Click|No Click|\n",
    "|--|--|--|\n",
    "|Advertisement A|36|14|\n",
    "|Advertisement B|30|25|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi-Square Test Statistic\n",
    "- $\\chi^2$ test statistic\n",
    "- Always positive\n",
    "- Like t-distribution: 1 parameter = degree of freedom\n",
    "- Like t, also has location/scale(is avaliable in Scipy) - default loc = 0,scale = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\chi^2 = \\sum_{i}^{}\\frac{(\\text{observed}_{i} -\\text{expected}_{i})^2}{\\text{expected}_{i}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- i = every cell of table\n",
    "\n",
    "\n",
    "|[]()|Click|No Click|Click + No Click|\n",
    "|--|--|--|--|\n",
    "|Advertisement A|36|14|50|\n",
    "|Advertisement B|30|25|55|\n",
    "|Ad A+ Ad B|66|39|105|\n",
    "\n",
    "- i = (Ad A,Click)\n",
    "- $\\text{observed}_{i}$ = 36\n",
    "- $\\text{expected}_{i}$ = ( number times Ad A is shown )*p(click) = 50*(66/105) = 31.429\n",
    "\n",
    "- i = (Ad A,No Click)\n",
    "- $\\text{observed}_{i}$ = 14\n",
    "- $\\text{expected}_{i}$ = ( number times Ad A is shown )*p(No click) = 50*(39/105) = 18.571 = (row 1)*(col 2)/N\n",
    "\n",
    "- $\\chi^2$ = $(36-31.429)^2/31.429+(14-18.571)^2/18.571+(30-34.571)^2/34.571+(25-20.429)^2/20.429=3.418$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## shortcut\n",
    "- only works for 2x2 table\n",
    "\n",
    "$$\n",
    "\\chi^2 = \\frac{(ad-bc)^2(a+b+c+d)}{(a+b)(c+d)(a+c)(b+d)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's next?\n",
    "- Distribution is >= 0\n",
    "- Extreme is when observed far away from expected\n",
    "- so $\\chi^2$ is large\n",
    "- so 1- CDF($\\chi^2$) gives us a small number\n",
    "- this is the p-vale\n",
    "- as is typical, if p-value < $\\alpha$ , then Ad A and Ad B are significantly different"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# T is table\n",
    "scipy.stats.chi2_contingency(T,correction=False)\n",
    "```\n",
    "\n",
    "- what's this correction?\n",
    "- Chi square test statistics asymptotically approaches the chi-square distribution\n",
    "- when N = $\\infty$\n",
    "- same situation as CLT(central limit theory)\n",
    "- same distirbution when estimating $\\mu$\n",
    "- yates correction(set correction = True in Scipy)\n",
    "- Fisher's exact test(different test,same data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import chi2, chi2_contingency\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class DataGenerator:\n",
    "  def __init__(self, p1, p2):\n",
    "    # p1,p2 click probability of group1,group2\n",
    "    self.p1 = p1\n",
    "    self.p2 = p2\n",
    "    \n",
    "    \n",
    "  def next(self):\n",
    "    # return click(1),no click(0)\n",
    "    click1 = 1 if (np.random.random() < self.p1) else 0\n",
    "    click2 = 1 if (np.random.random() < self.p2) else 0\n",
    "    return click1, click2\n",
    "  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "# contingency table\n",
    "#        click       no click\n",
    "#------------------------------\n",
    "# ad A |   a            b\n",
    "# ad B |   c            d\n",
    "#\n",
    "# chi^2 = (ad - bc)^2 (a + b + c + d) / [ (a + b)(c + d)(a + c)(b + d)]\n",
    "# degrees of freedom = (#cols - 1) x (#rows - 1) = (2 - 1)(2 - 1) = 1\n",
    "\n",
    "# short example\n",
    "\n",
    "# T = np.array([[36, 14], [30, 25]])\n",
    "# c2 = np.linalg.det(T)**2 * T.sum() / ( T[0].sum()*T[1].sum()*T[:,0].sum()*T[:,1].sum() )\n",
    "# p_value = 1 - chi2.cdf(x=c2, df=1)\n",
    "\n",
    "# equivalent:\n",
    "# (36-31.429)**2/31.429+(14-18.571)**2/18.571 + (30-34.571)**2/34.571 + (25-20.429)**2/20.429\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- only works for 2x2 table\n",
    "\n",
    "$$\n",
    "\\chi^2 = \\frac{(ad-bc)^2(a+b+c+d)}{(a+b)(c+d)(a+c)(b+d)}\n",
    "$$\n",
    "```python\n",
    "def get_p_value(T):\n",
    "  # same as scipy.stats.chi2_contingency(T, correction=False)\n",
    "  det = T[0,0]*T[1,1] - T[0,1]*T[1,0]\n",
    "  c2 = float(det) / T[0].sum() * det / T[1].sum() * T.sum() / T[:,0].sum() / T[:,1].sum()\n",
    "  p = 1 - chi2.cdf(x=c2, df=1)\n",
    "  return p\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def run_experiment(p1, p2, N):\n",
    "  data = DataGenerator(p1, p2)\n",
    "  p_values = np.empty(N)\n",
    "  T = np.zeros((2, 2)).astype(np.float32)\n",
    "  for i in range(N):\n",
    "    c1, c2 = data.next()\n",
    "    T[0,c1] += 1\n",
    "    T[1,c2] += 1\n",
    "    # ignore the first 10 values\n",
    "    if i < 10:\n",
    "      p_values[i] = None\n",
    "    else:\n",
    "      p_values[i] = get_p_value(T)\n",
    "  plt.plot(p_values)\n",
    "  plt.plot(np.ones(N)*0.05)\n",
    "  plt.show()\n",
    "\n",
    "run_experiment(0.1, 0.11, 20000)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "[t_distribution calc](http://www.dmbru.dentistry.ubc.ca/Calculating_Companion/applets/t_distribution/t_distribution.php)\n",
    "![](http://kisi.deu.edu.tr/joshua.cowley/StudentTTable.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
