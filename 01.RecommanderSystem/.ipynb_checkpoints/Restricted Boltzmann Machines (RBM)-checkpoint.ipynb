{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restricted Boltzmann Machines for Collaborative Filtering\n",
    "- Ruslan Salakhutdinov and Andriy Mnih are authours of this paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RBM architecture\n",
    "\n",
    "![](https://viblo.asia/uploads/e416dffb-642d-4a95-ae27-85cb1b57511b.png)\n",
    "\n",
    "[RBM blog](https://viblo.asia/p/restricted-boltzmann-machine-an-overview-aWj531oQZ6m)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Visible - v\n",
    "- Hidden - h\n",
    "- Can calculate h from v (v -> h)\n",
    "- Can also calculate v from h! (h -> v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bernoulli RBMs\n",
    "\n",
    "- Both visible and hidden units can only take on the values 0 and 1\n",
    "- What's Bernoulli?\n",
    "    - Binary random variable - only 2 outcomes\n",
    "    - Coin toss\n",
    "    - whether or not user clicks on advertisement\n",
    "    - whether or not user signs up for website\n",
    "- very useful for web-based applications\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key calculations\n",
    "\n",
    "- very intuitive\n",
    "- How to calculate h from v\n",
    "\n",
    "$$\n",
    "\\text{vector form} = p(h=1 |v) = \\sigma(W^{T}v+c)\\\\\n",
    "\\text{Scalar form} = p(h_{j} = 1|v) = \\sigma(\\sum_{i=1}^{D}W_{ij}v_{i}+c_{j}), i = 1...D,j = 1,...M\\\\\n",
    "\\text{len}(v) = D, \\text{len}(h) = M\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- going from h to v\n",
    "- W is a shared weight\n",
    "\n",
    "$$\n",
    "\\text{vector form} = p(v=1 |h) = \\sigma(Wh+b)\\\\\n",
    "\\text{Scalar form} = p(v_{i} = 1|h) = \\sigma(\\sum_{j=1}^{M}W_{ij}h_{j}+b_{i}), i = 1...D,j = 1,...M\\\\\n",
    "\\text{len}(v) = D, \\text{len}(h) = M\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Both\n",
    "\n",
    "- we only get probabilities\n",
    "- What if I want the actual h?\n",
    "- There's no fixed value - it's a nonsense question\n",
    "- It's like a coin- I can flip the coin to grab a sample\n",
    "- e.g if p($h_{i}=1$|v) = 0.5\n",
    "- sample = np.random.random(p.shape) < p\n",
    "\n",
    "$$\n",
    "p(h=1 |v) = \\sigma(W^{T}v+c)\\\\\n",
    "p(v=1 |h) = \\sigma(Wh+b)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relaxing the Bernoulli constraint\n",
    "\n",
    "- when going from h->v, simply use p(h=1|v) itself as input\n",
    "\n",
    "$$\n",
    "\\tilde{h} = p(h=1|v) = \\sigma(W^{T}v+c)\\\\\n",
    "p(v' = 1|h) = \\sigma(W\\tilde{h}+b)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison to Autoencoder\n",
    "- looks familiar\n",
    "\n",
    "$$\n",
    "h = \\sigma(W^{T}v + c)\\\\\n",
    "v' = \\sigma(Wh + b)\n",
    "$$\n",
    "\n",
    "![](https://image.slidesharecdn.com/ucl-irdm-deeplearning-160429080538/95/deep-learning-55-638.jpg?cb=1461917930)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- v -> h->v' in RBM, the cross entropy (distance between v and v') will go down as we train, even though we don't optimize it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation Behind RBMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boltzmann Machine\n",
    "- Energy of a Boltzmann machine\n",
    "- Goal is to find some equilibrium\n",
    "- Looks like a neural network equation, has a weight matrix, bias term\n",
    "\n",
    "$$\n",
    "E = -(\\sum_{i,j}^{}W_{ij}s_{i}s_{j}+ \\sum_{i}^{}b_{i}s_{i})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Boltzmann Machine\n",
    "- Boltzmann machines are difficult to train\n",
    "- only works on trivial examples\n",
    "- Restricted Boltzmann machines do train well, and scale up to non-trivial problems\n",
    "\n",
    "$$\n",
    "G = \\sum_{v}^{}P^{+}(v)ln(\\frac{P^{+}(v)}{P^{-}(v)})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restricted Boltzmann Machine\n",
    "- Discard any connections between hidden-hidden and visible-visible\n",
    "\n",
    "![](https://cn.bing.com/th?id=OIP.TWt5Uc1QlbKUoJvObnUzgQHaDi&pid=Api&rs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Energy of an RBM\n",
    "\n",
    "$$\n",
    "E(v,h) = -(\\sum_{i=1}^{D}\\sum_{j=1}^{M}W_{ij}v_{i}h_{j}+\\sum_{i=1}^{D}b_{i}v_{i}+\\sum_{j=1}^{M}c_{j}h_{j})\\\\\n",
    "E(v,h) = -(v^{T}Wh+b^{T}v+c^{T}h)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action plan\n",
    "- How does the energy function lead us to a probabilistic model?\n",
    "- How does the probabilistic model lead us to the neural network equations?\n",
    "    - It's quite remarkable that this energy function could lead us back to the same neural network equations we are already familiar with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability Model\n",
    "$$\n",
    "p(v,h) \\propto e^{-E(v,h)}\\\\\n",
    "p(v,h) = \\frac{1}{Z}e^{-E(v,h)}, Z = \\sum_{v}^{}\\sum_{h}^{}e^{-E(v,h)}\\\\\n",
    "\\text{so that}: \\sum_{v}^{}\\sum_{h}^{}p(v,h) = 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why?\n",
    "- General outline: $p_{i}$ is the probability that a system is in a microstate with energy $E_{i}$\n",
    "- T = temperature, Z = partition function\n",
    "\n",
    "$$\n",
    "p_{i} \\propto e^{-E_{i}/(kT)}\\\\\n",
    "p_{i} = \\frac{1}{Z}e^{-E_{i}/(kT)}, Z = \\sum_{i}^{}e^{-E_{i}/(kT)}\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intractability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intractability\n",
    "- What does it mean to sum over v and sum over h?\n",
    "- v and h are Bernoulli vectors(vectors of 0s and 1s)\n",
    "- If v has length D and h has length M, the number of total possibilities is\n",
    "- $2^D$ x $2^M$ = $2^{D+M}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "p(v,h) = \\frac{1}{Z}e^{-E(v,h)}, Z = \\sum_{v}^{}\\sum_{h}^{}e^{-E(v,h)}\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple calculation\n",
    "- MNIST contains 28x28 images, so D = 784\n",
    "- we can choose M, let's pick M = 100 (hidden units)\n",
    "- what's the total number of possible values of v and h?\n",
    "- $2^{784} \\times 2^{100} = 1.3 \\times 10^{266}$\n",
    "- How big is this number?\n",
    "- Image how much money a billionaire has:1 billion = 1 x $10^9$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execise\n",
    "- Calculate how much time it would take you to sum over all possible values of v and h\n",
    "- Compute 100 or 1000 steps, then extrapolate to determine how long it would take in total\n",
    "\n",
    "```python\n",
    "z = 0\n",
    "for v:\n",
    "    for h:\n",
    "        z += exp(-(v.T.dot(W).dot(h) + b.dot(v) + c.dot(h)))\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Equations\n",
    "- How does our probability model lead us to the neural network equations we showed earlier?\n",
    "- Remarkable that statistical mechanics lead us back to the equations we already know and love\n",
    "- No wonder that research in this area was strong\n",
    "\n",
    "$$\n",
    "E(v,h) = -(v^{T}Wh + b^{T}v + c^Th) \\\\\n",
    "p(h=1 |v) = \\sigma(W^{T}v+c)\\\\\n",
    "p(v=1 |h) = \\sigma(Wh+b)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes rule\n",
    "- we can start with the basic rules of probability\n",
    "\n",
    "$$\n",
    "p(v|h) = p(v,h)/p(h)\\\\\n",
    "p(h|v) = p(v,h)/p(v)\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marginals\n",
    "- we can calculate the denominator from the numerator\n",
    "$$\n",
    "p(v) = \\sum_{h}^{}p(v,h),p(h) = \\sum_{v}^{}p(v,h)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plug in what we know\n",
    "\n",
    "$$\n",
    "p(v,h) = \\frac{1}{Z}exp(v^{T}Wh + b^{T}v + c^Th)\\\\\n",
    "p(v) = \\sum_{h}^{}\\frac{1}{Z}exp(v^{T}Wh + b^{T}v + c^Th)\\\\\n",
    "p(h|v) = \\frac{exp(v^{T}Wh + b^{T}v + c^Th)}{\\sum_{h}^{}exp(v^{T}Wh + b^{T}v + c^Th)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplify\n",
    "- The denominator is simply another normalizing constant\n",
    "\n",
    "$$\n",
    "p(h|v) = \\frac{1}{z'}exp(v^{T}Wh + b^{T}v + c^Th)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write it in scalar form\n",
    "\n",
    "$$\n",
    "p(h|v) = \\frac{1}{z'}exp(\\sum_{i=1}^{D}\\sum_{j=1}^{M}W_{ij}v_{i}h_{j}+\\sum_{i=1}^{D}b_{i}v_{i}+\\sum_{j=1}^{M}c_{j}h_{j})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exponent rule\n",
    "- exp(A+B) = exp(A)exp(B)\n",
    "\n",
    "$$\n",
    "p(h|v) = \\frac{1}{z'}exp(\\sum_{i=1}^{D}b_{i}v_{i})\\prod_{j=1}^{M}exp(\\sum_{i=1}^{D}W_{ij}v_{i}h_{j}+c_{j}h_{j})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Absorb Normalizing Constant\n",
    "- Anything that doesn't depend on h can be absorbed\n",
    "- iid (independence , identical distributed ) h and v \n",
    "\n",
    "$$\n",
    "p(h|v) = \\frac{1}{Z''}\\prod_{j=1}^{M}exp(\\sum_{i=1}^{D}W_{ij}v_{i}h_{j}+c_{j}h_{j})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Factor out $h_{j}$\n",
    "\n",
    "$$\n",
    "p(h|v) =  \\frac{1}{Z''}\\prod_{j=1}^{M}exp(h_{j}\\bigg\\{\\sum_{i=1}^{D}W_{ij}v_{i}+c_{j} \\bigg\\})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Independence\n",
    "- Key point: if A and B are independent, then p(A,B) = p(A)p(B)  \n",
    "- we can see that p(h|v) factors out where each p(h_{j}|v) is independent of the others - let's just look at a single one  \n",
    "- __Make sense graphically - hidden units can't connect to other hidden units__\n",
    "$$\n",
    "p(h_{j}|v) =  \\frac{1}{Z'''}exp(h_{j}\\bigg\\{\\sum_{i=1}^{D}W_{ij}v_{i}+c_{j} \\bigg\\})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It's Bernoulli\n",
    "\n",
    "- $h_{j}$ can only ever be 0 or 1\n",
    "- Let's just plug it in \n",
    "\n",
    "$$\n",
    "p(h_{j}= 1|v) = \\frac{1}{Z'''}exp(\\bigg\\{\\sum_{i=1}^{D}W_{ij}v_{i}+c_{j} \\bigg\\})\\\\\n",
    "p(h_{j}= 0|v) = \\frac{1}{Z'''}exp(0) = \\frac{1}{Z'''}\\\\\n",
    "$$\n",
    "\n",
    "- 0 and 1 are the only possibilities, therefore, they must sum to 1\n",
    "- we have found the normalizing constant Z'''  \n",
    "\n",
    "$$\n",
    "p(h_{j}=1|v) + p(h_{j}=0|v) = 1\\\\\n",
    "\\frac{1}{Z'''}exp(\\sum_{i=1}^{D}W_{ij}v_{i}+c_{j} ) + \\frac{1}{Z'''} = 1\\\\\n",
    "Z''' = 1 + exp(\\sum_{i=1}^{D}W_{ij}v_{i}+c_{j})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plug it back in\n",
    "- we arrive at our usual neural network equation\n",
    "\n",
    "$$\n",
    "p(h_{j}=1 |v) = \\frac{exp(\\sum_{i=1}^{D}W_{ij}v_{i}+c_{j})}{1 + exp(\\sum_{i=1}^{D}W_{ij}v_{i}+c_{j})} \\\\\n",
    " = \\sigma(\\sum_{i=1}^{D}W_{ij}v_{i}+c_{j})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full vector form\n",
    "- Remember, this abuses notation a little bit\n",
    "- It's not a probability, but __`a vector of probabilities`__\n",
    "\n",
    "$$\n",
    "p(h=1|v) = \\sigma(W^Tv +c)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training an RBM(part 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to train an RBM\n",
    "- More complicated than usual(not just plain gradient descent)\n",
    "- Intuitively, we konw some quantities are intractable to calculate\n",
    "- start by discussing what we'd like to do\n",
    "- end with how we approximate it instead\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Likelihood Estimation\n",
    "- we want W,b,c, to maximize the likelihood\n",
    "- can take the log since log is monotonically increasing\n",
    "\n",
    "$$\n",
    "\\text{Maximize }p(v) \\text{ wrt } W,b,c \\\\\n",
    "W,b,c = argmax_{W,b,c}p(v;W,b,c)\\\\\n",
    "W,b,c = argmax_{W,b,c}logp(v;W,b,c)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why does maxminum likelihood make sense?\n",
    "- we measure the heights of all students in our class\n",
    "    - $x_{1},x_{2},...,x_{n}$\n",
    "- model it as Gaussian\n",
    "    - find $\\mu,\\sigma^2$\n",
    "- as usual, solve by setting derivative to 0    \n",
    "\n",
    "$$\n",
    "\\mu,\\sigma^2 = argmax_{\\mu,\\sigma^2}log\\prod_{i=1}^{N}p(x_{i};\\mu,\\sigma^2)\\\\\n",
    "\\text{solution}: \\mu = \\frac{1}{N}\\sum_{i=1}^{N}x_{i},\\sigma^2 = \\frac{1}{N}\\sum_{i=1}^{N}(x_{i}-\\mu)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another Example\n",
    "- Gaussian Mixture Model(GMM)\n",
    "- Used when distribution is multimodal\n",
    "- multiple humps in histogram\n",
    "\n",
    "![](https://www.researchgate.net/profile/Gregory_Valiant/publication/220427369/figure/fig1/AS:668920864309268@1536494570651/The-Gaussian-approximations-of-the-heights-of-adult-women-red-and-men-blue-Can-one.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GMM(Gaussian Mixture Model)\n",
    "- need to introduce a hidden variable $h_{j}$ to tell us which Gaussian a datapoint belongs to\n",
    "- Assuming we have M Gaussians, the distribution of x is \n",
    "\n",
    "$$\n",
    "p(x) = \\sum_{j=1}^{M}p(h_{j})p(x|h_{j}) = \\sum_{j=1}^{M}\\pi_{j}\\frac{1}{\\sqrt{2\\pi\\sigma^2}}exp(\\frac{-(x-\\mu_{j})^2}{2\\sigma^2})\n",
    "$$\n",
    "\n",
    "- $\\pi_{j}$ is weight \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2 sets of variables: x(observed), h(unobserved)\n",
    "- we still want to maximize p(x), wrt, $\\pi,\\mu,\\sigma^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back to RBM\n",
    "- Hopefully you're convinced it makes sense to maximize p(v)(or equivalently logp(v))\n",
    "- If we could build up this expression, Theano or Tensorflow would automatically find the gradient and we would be done\n",
    "- Problem: building up this expression is intractable\n",
    "\n",
    "$$\n",
    "p(v) = \\sum_{h}^{}\\frac{1}{Z}exp(-\\bigg\\{v^{T}Wh + b^{T}v + c^Th\\bigg \\})\\\\\n",
    "Z = \\sum_{v}^{}\\sum_{h}^{}exp(-\\bigg\\{v^{T}Wh + b^{T}v + c^Th\\bigg \\})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Free Energy\n",
    "- What should we do instead? Let's introduce a new quantity called free energy?\n",
    "- Totally not obvious why it's useful, buy you'll see\n",
    "\n",
    "$$\n",
    "F(v) = -log \\sum_{h}^{}e^{-E(v,h)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "E(v,h) = -(\\sum_{i=1}^{D}\\sum_{j=1}^{M}W_{ij}v_{i}h_{j}+\\sum_{i=1}^{D}b_{i}v_{i}+\\sum_{j=1}^{M}c_{j}h_{j})\\\\\n",
    "E(v,h) = -(v^{T}Wh+b^{T}v+c^{T}h)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Term\n",
    "- Can this allow us to write p(v) in terms of F(v)?\n",
    "- Exercise: \n",
    "\n",
    "$$\n",
    "F(v) = -log \\sum_{h}^{}e^{-E(v,h)}\\\\\n",
    "p(v) = \\frac{1}{Z}\\sum_{h}^{}e^{-E(v,h)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulate F(v)\n",
    "\n",
    "- take the negative of both sides\n",
    "\n",
    "$$\n",
    "- F(v) = log \\sum_{h}^{}e^{-E(v,h)}\\\\\n",
    "$$\n",
    "\n",
    "- Exponentiate both sides\n",
    "$$\n",
    "e^{-F(v)} = \\sum_{h}^{}e^{-E(v,h)}, \\text{since }e^{log(x)} = x \\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "p(v) = \\frac{1}{Z}e^{-F(v)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redefine Z\n",
    "\n",
    "$$\n",
    "Z = \\sum_{v}^{}e^{-F(v)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent\n",
    "- Let's pretend p(v) is tractable and that gradient descent is possible\n",
    "- What will the update look like?\n",
    "- Find derivative wrt arbitrary parameter: $W_{ij},b_{i},c_{j}$ - doesn't matter\n",
    "\n",
    "$$\n",
    "\\frac{\\partial{logp(v)}}{\\partial \\theta} = \\frac{\\partial}{\\partial{\\theta}}(log\\bigg\\{ \\frac{e^{-F(v)}}{Z} \\bigg\\})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- since log(A/B) = log(A) - log(B)\n",
    "\n",
    "$$\n",
    "\\frac{\\partial{logp(v)}}{\\partial{\\theta}} = \\frac{\\partial}{\\partial\\theta}(-F(v)- logZ)\\\\\n",
    "= -\\frac{\\partial{F(v)}}{\\partial\\theta} - \\frac{\\partial}{\\partial\\theta}logZ\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- use the log rule\n",
    "\n",
    "$$\n",
    "\\frac{\\partial{logp(v)}}{\\partial{\\theta}} = \\frac{\\partial}{\\partial\\theta}(-F(v)- logZ)\\\\\n",
    "= -\\frac{\\partial{F(v)}}{\\partial\\theta} - \\frac{\\partial}{\\partial\\theta}logZ\n",
    "= -\\frac{\\partial{F(v)}}{\\partial\\theta} - \\frac{1}{Z}\\frac{\\partial}{\\partial\\theta}Z\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "-\\frac{\\partial{F(v)}}{\\partial\\theta} - \\frac{\\partial}{\\partial\\theta}logZ\\\\\n",
    "= -\\frac{\\partial{F(v)}}{\\partial\\theta} - \\frac{1}{Z}\\frac{\\partial}{\\partial\\theta}\\sum_{v'}^{}e^{-F(v')}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- move derivative inside the sum\n",
    "\n",
    "$$\n",
    "= -\\frac{\\partial{F(v)}}{\\partial\\theta} - \\frac{1}{Z}\\sum_{v'}^{}\\frac{\\partial}{\\partial\\theta}e^{-F(v')}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- use exponent rule and chain rule\n",
    "\n",
    "$$\n",
    "= -\\frac{\\partial{F(v)}}{\\partial\\theta} - \\frac{1}{Z}\\sum_{v'}^{}e^{-F(v')}\\frac{\\partial{(-F(v'))}}{\\partial\\theta}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- move Z back into summation\n",
    "\n",
    "\n",
    "$$\n",
    "= -\\frac{\\partial{F(v)}}{\\partial\\theta} - \\sum_{v'}^{}\\frac{1}{Z}e^{-F(v')}\\frac{\\partial{(-F(v'))}}{\\partial\\theta}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$$\n",
    "\\frac{\\partial{logp(v)}}{\\partial{\\theta}} = -\\frac{\\partial{F(v)}}{\\partial{\\theta}}+ \\sum_{v'}^{}p(v')\\frac{\\partial{F(v')}}{\\partial{\\theta}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Flip all the signs(we want something to minimize rather than maximize\n",
    "- gradient descent rather than gradient ascent\n",
    "- maximize p(v) is equivalent to minimizing -logp(v)\n",
    "    - both mean squared error and cross entropy are negative log likelihoods\n",
    "\n",
    "$$\n",
    "-\\frac{\\partial{logp(v)}}{\\partial{\\theta}} = \\frac{\\partial{F(v)}}{\\partial{\\theta}}-\\sum_{v'}^{}p(v')\\frac{\\partial{F(v')}}{\\partial{\\theta}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation\n",
    "- well known result for energy based models such as RBMs\n",
    "- first term makes seeing v more likely , v feature vector\n",
    "- second term makes seeing every possible v' less likely (weighted by p(v'))\n",
    "- Imagine: bad model makes v'(never observed) very likely - p(v') is high\n",
    "    - This gradient update exactly corrects it\n",
    "\n",
    "\n",
    "$$\n",
    "\\text{first term: positive phase :} \\frac{\\partial{F(v)}}{\\partial{\\theta}}\\\\\n",
    "\\text{second term: negative phase :} -\\sum_{v'}^{}p(v')\\frac{\\partial{F(v')}}{\\partial{\\theta}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training an RBM (part 2)\n",
    "\n",
    "\n",
    "$$\n",
    "-\\frac{\\partial{logp(v)}}{\\partial{\\theta}} = \\frac{\\partial{F(v)}}{\\partial{\\theta}}-\\sum_{v'}^{}p(v')\\frac{\\partial{F(v')}}{\\partial{\\theta}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Value\n",
    "- 2nd term is exactly an expected value, Recall the general definition of expected value\n",
    "\n",
    "$$\n",
    "E(f(x)) = \\sum_{x}^{}p(x)f(x)\\\\\n",
    "-\\frac{\\partial{logp(v)}}{\\partial{\\theta}} = \\frac{\\partial{F(v)}}{\\partial{\\theta}}-E\\bigg\\{\\frac{\\partial{F(v')}}{\\partial{\\theta}}\\bigg\\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximating expected value\n",
    "- Expected value is a mean\n",
    "- Approximate means using sample means\n",
    "- How do we generate these samples?\n",
    "\n",
    "$$\n",
    "E(f(x)) \\approx \\frac{1}{N}\\sum_{n}^{}f(x_{n})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to sample\n",
    "- just go one round and only use that one sample\n",
    "- v ->p(h|v) -> h ~p(h|v) -> p(v'|h)->v' ~p(v'|h)\n",
    "\n",
    "$$\n",
    "v \\rightarrow h \\rightarrow v'\\\\\n",
    "-\\frac{\\partial{logp(v)}}{\\partial{\\theta}} \\approx \\frac{\\partial{F(v)}}{\\partial{\\theta}}-\\frac{\\partial{F(v')}}{\\partial{\\theta}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contrastive Divergence\n",
    "- Abbreviated as CD-k, to mean k steps of Gibbs sampling were performed to get v'\n",
    "- we will do CD-1(you can try more and see if your results improve)\n",
    "- one epoch  \n",
    "\n",
    "```python\n",
    "for v in dataset:\n",
    "    p(h=1|v) = sigmoid(W.T.dot(v)+c)\n",
    "    h = sample_from(p(h=1|v))\n",
    "    p(v'=1|h) = sigmoid(W.got(h)+b)\n",
    "    v' = sample_from(p(v'=1|h))\n",
    "    param = param - learning_rate*(grad(F(v))-grad(F(v')))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theano and Tensorflow\n",
    "- gradients will be calculated \n",
    "- in other words, our actual function will just be L = F(v)- F(v')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __`Fake loss`__\n",
    "\n",
    "- The gradient of our loss is approximated by the gradient of L\n",
    "$$\n",
    "\\frac{\\partial{-logp(v)}}{\\partial{\\theta}} \\approx\\frac{\\partial L}{\\partial\\theta}\\approx \\frac{\\partial{F(v)}}{\\partial{\\theta}}-\\frac{\\partial{F(v')}}{\\partial{\\theta}}\n",
    "$$\n",
    "\n",
    "- we don't express gradients explicitly in Theano or Tensorflow, therefore, we only want L itself\n",
    "\n",
    "$$\n",
    "\\int{\\frac{\\partial L}{\\partial\\theta}d\\theta } = \\int{\\frac{\\partial F(v)}{\\partial \\theta}}d\\theta - \\int{\\frac{\\partial F(v')}{\\partial\\theta}}d\\theta\\\\\n",
    "L = F(v) - F(v')\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## But wait\n",
    "- our free energy expression still appears to be intractable\n",
    "\n",
    "\n",
    "$$\n",
    "F(v) = -log \\sum_{h}^{}e^{-E(v,h)}\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Free Energy\n",
    "- How can we calculate F(v) in a way that's not intractable\n",
    "- Last theoretical lecture before you're able to write an RBM in code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "F(v) = -log \\sum_{h}^{}e^{v^{T}Wh+b^Tv+c^Th}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $b^Tv$ term doesn't depend on h, move it outside\n",
    "\n",
    "$$\n",
    "F(v) = -log e^{b^Tv} \\sum_{h}^{}e^{v^{T}Wh+c^Th}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- use the log(AB) = log(A) + log(B)\n",
    "\n",
    "$$\n",
    "F(v) = -b^Tv -log \\sum_{h}^{}e^{v^{T}Wh+c^Th}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- unvectorize h\n",
    "\n",
    "$$\n",
    "F(v) = -b^Tv -log \\sum_{h}^{}exp(\\sum_{j=1}^{M}v^{T}W_{:,j}h_{j}+c_{j}h_{j})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bring summation outside exponent\n",
    "- Factor out $h_{j}$\n",
    "\n",
    "$$\n",
    "F(v) = -b^Tv -log \\sum_{h}^{}\\prod_{j=1}^{M}exp h_{j}(v^{T}W_{:,j}h_{j}+c_{j})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What terms actually need to be summed?\n",
    "- If M = 2\n",
    "    - possible values of h ={00,01,10,11}\n",
    "- If M = 3\n",
    "    - possible values of h ={000,001,010,011,100,101,110,111}\n",
    "    \n",
    "- as you konw, this is exponential $2^M$\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- simplified version\n",
    "\n",
    "$$\n",
    "F(v) = -b^Tv -log \\sum_{h}^{}\\prod_{j=1}^{M}exp h_{j}(v^{T}W_{:,j}h_{j}+c_{j})\\\\\n",
    "\\sum_{h}^{}\\prod_{j=1}^{M}exp h_{j}(v^{T}W_{:,j}h_{j}+c_{j}) = \\sum_{h}^{}\\prod_{j=1}^{M}e^{h_{j}u_{j}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's plug in the values of h for M = 2\n",
    "\n",
    "$$\n",
    "\\sum_{h}^{}\\prod_{j=1}^{M}exp h_{j}(v^{T}W_{:,j}h_{j}+c_{j}) = \\sum_{h}^{}\\prod_{j=1}^{M}e^{h_{j}u_{j}}\\\\\n",
    "e^{0u_{1}}e^{0u_{2}} + e^{0u_{1}}e^{1u_{2}}+ e^{1u_{1}}e^{0u_{2}}+e^{1u_{1}}e^{1u_{2}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Factorization\n",
    "\n",
    "$$\n",
    "e^{0u_{1}}e^{0u_{2}} + e^{0u_{1}}e^{1u_{2}}+ e^{1u_{1}}e^{0u_{2}}+e^{1u_{1}}e^{1u_{2}}\n",
    "= (e^{0u_{1}}+e^{1u_{1}})(e^{0u_{2}}+e^{1u_{2}})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- M = 3\n",
    "\n",
    "$$\n",
    "= (e^{0u_{1}}+e^{1u_{1}})(e^{0u_{2}}+e^{1u_{2}})(e^{0u_{3}}+e^{1u_{3}})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Can we generalize this pattern for any value of M? sure\n",
    "- This is going by quite fast, \n",
    "- more generally known as the sum-product rule and appears when working with Bayesian networks\n",
    "\n",
    "$$\n",
    "\\sum_{h}^{}\\prod_{j=1}^{M}e^{h_{j}u_{j}} = \\prod_{j=1}^{M}\\sum_{h_{j}=\\big\\{ 0,1\\big\\}}^{}e^{h_{j}u_{j}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Plug our result back in\n",
    "\n",
    "$$\n",
    "F(v) = -b^Tv -log \\sum_{h}^{}\\prod_{j=1}^{M}exp h_{j}(v^{T}W_{:,j}h_{j}+c_{j})\\\\\n",
    "F(v) = -b^Tv -log \\prod_{j=1}^{M}\\sum_{h_{j}=\\big\\{ 0,1\\big\\}}^{} exp h_{j}(v^TW_{:,j}+c_{j})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- apply log rule log(AB) = log(A) + log(B)\n",
    "\n",
    "$$\n",
    "F(v) = -b^Tv -log \\prod_{j=1}^{M}\\sum_{h_{j}=\\big\\{ 0,1\\big\\}}^{} exp h_{j}(v^TW_{:,j}+c_{j})\\\\ \n",
    "F(v) = -b^Tv - \\sum_{j=1}^{M}log\\sum_{h_{j}= \\big\\{ 0,1\\big\\}}^{}exp h_{j}(v^TW_{:,j}+c_{j})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $h_{j}$ can only take on 2 values - 0 and 1\n",
    "- Result in linear in M rather than exponential\n",
    "\n",
    "$$\n",
    "F(v) = -b^Tv - \\sum_{j=1}^{M}log \\big\\{ 1+exp (v^TW_{:,j}+c_{j}) \\big\\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical RBM for recommender system Ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expanding Bernoulli RBM\n",
    "- Why won't Bernoulli work?\n",
    "- Bernoulli must be 0 or 1(or between 0 and 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical RBM\n",
    "- Visible units represent a K-class categorical distribution\n",
    "- Ratings go from 0.5 -> 5 = 10 categories\n",
    "\n",
    "![](https://media.springernature.com/lw785/springer-static/image/chp%3A10.1007%2F978-3-319-73317-3_45/MediaObjects/462481_1_En_45_Fig1_HTML.gif)\n",
    "[RBM paper](https://link.springer.com/chapter/10.1007/978-3-319-73317-3_45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Neural Network Equations\n",
    "- Hidden units remain as Bernoulli\n",
    "\n",
    "$$\n",
    "p(h_{j}=1|v) = \\sigma(\\sum_{k=1}^{K}\\sum_{i=1}^{D}W_{ij}^{k}v_{i}^{k}+c_{j})\\\\\n",
    "p(v_{i}^{k}=1|h) = softmax(\\sum_{j=1}^{M}W_{ij}^{k}h_{j}^{k}+b_{i}^{k})\\\\\n",
    "\\text{where: } softmax(\\alpha_{i}^{k}) = \\frac{exp(\\alpha_{i}^{k})}{\\sum_{k'=1}^{K}exp(\\alpha_{i}^{k'})}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shapes\n",
    "- very useful for thinking about how data is structured/implementation\n",
    "- h = vector of size M\n",
    "- v = 2-D array of size D x K\n",
    "- W = 3-D array of size D x K x M\n",
    "- b = 2-D array of size D x K\n",
    "- c = vector of size M\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization\n",
    "- can you vectorize these equations?\n",
    "- quite a dot product or matrix multiply because we sum over two dimensions\n",
    "- like a double dot product \n",
    "- Let's use the same notation- $W^{T}v$ and $b^{T}v$ = but remember it's actually a double sum \n",
    "\n",
    "$$\n",
    "\\sum_{k=1}^{K}\\sum_{i=1}^{D}W_{ij}^{k}v_{i}^{k}\\\\\n",
    "\\sum_{k=1}^{K}\\sum_{i=1}^{D}b_{i}^{k}v_{i}^{k}\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naming conventions\n",
    "- normally with recommender systems\n",
    "    - N = number of users\n",
    "    - M = number of movies\n",
    "    - K = latent dimension\n",
    "- with RBMs - too many dimensions to represent\n",
    "- we'll stick to more typical deep learning conventions\n",
    "    - D = input dimensionality = number of movies\n",
    "    - K = number of classes = number of possible ratings\n",
    "    - M = number of hidden units\n",
    "    - N = number of samples = number of users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "- As usual, now that we have our model, we want to know how to train it \n",
    "- Start with energy again\n",
    "- Remember, this looks the same, but it's not the same because implicitly there is a double dot product\n",
    "\n",
    "$$\n",
    "E(v,h) = -\\bigg\\{v^{T}Wh + b^{T}v + c^{T}h \\bigg\\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Free Energy\n",
    "- E(v,h) is just a scalar so this definition doesn't change\n",
    "\n",
    "$$\n",
    "F(v) = -log \\sum_{h}^{}e^{-E(v,h)}\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Plug in E\n",
    "\n",
    "$$\n",
    "F(v) = -log \\sum_{h}^{}e^{v^{T}Wh + b^{T}v + c^{T}h }\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Each addictive term is a scalar, so we can still move it outside sum like before\n",
    "\n",
    "$$\n",
    "F(v) = -log e^{b^{T}v}\\sum_{h}^{}e^{v^{T}Wh + c^{T}h }\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bring it outside the log\n",
    "\n",
    "$$\n",
    "F(v) = -b^{T}v-log\\sum_{h}^{}e^{v^{T}Wh + c^{T}h }\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- unvectorize h\n",
    "- W has 2: because it's 3-D\n",
    "\n",
    "$$\n",
    "F(v) = -b^{T}v-log\\sum_{h}^{}exp(\\sum_{j=1}^{M}v^{T}W_{:,:,j}h_{j} + c_{j}h_{j})\\\\\n",
    "F(v) = -b^{T}v-log\\sum_{h}^{}exp(\\sum_{j=1}^{M}h_{j}\\bigg\\{ v^{T}W_{:,:,j} + c_{j} \\bigg\\})\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Everything being multiplied by $h_{j}$ is a scalar- let's just call it $u_{j}$\n",
    "\n",
    "$$\n",
    "F(v) = -b^{T}v-log\\sum_{h}^{}exp(\\sum_{j=1}^{M}h_{j}u_{j})\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This is the same logic we applied before, therefore, we can arrive at the same conclusion\n",
    "\n",
    "$$\n",
    "F(v) = -b^{T}v-log\\sum_{h}^{}exp(\\sum_{j=1}^{M}h_{j}u_{j})\\\\\n",
    "F(v) = -b^{T}v-\\sum_{j=1}^{M}log\\bigg\\{ 1+exp(v^{T}W_{:,:,j}+c_{j}) \\bigg\\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow\n",
    "- cannot use tf.matmul - only works on 2-D array\n",
    "- does not work on 1-D arrays, nor 3-D array\n",
    "- must write your own double dot function using tf.tensordot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "- we've concluded that F(v) has the same form, therefore, trainign will generally be the same\n",
    "- but how do we deal with missing ratings?\n",
    "- v(i,k) = 1 if user rates move i the value k\n",
    "    - whatever rating class k corresponds to \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Ratings\n",
    "\n",
    "- consider a length -10 vector v(i) \n",
    "- If user rates movie i a 0.5\n",
    "    - v(i) = [1,0,0,0,0,0,0,0,0,0]\n",
    "- If user rates movie i a 5\n",
    "    - v(i) = [0,0,0,0,0,0,0,0,0,1]\n",
    "- If rating is missing\n",
    "    - v(i) = [0,0,0,0,,0,0,0,0,0](all zeros)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- our loss L = F(v) - F(v')\n",
    "- we have to mask v', so that if user did not rate movie i, then\n",
    "    - v(i) = [0,0,0,0,0,0,0,0,0,0](all zeros)\n",
    "    - v'(i) = [0,0,0,0,0,0,0,0,0,0](all zeros)\n",
    "    - L(i) = F(v(i)) - F(v'(i)) = 0\n",
    "- Difference is 0, gradient is 0, no changes made to parameters based on this movie    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predictions\n",
    "- normally, when we have softmax we just take the argmax to get the prediction\n",
    "- y = np.argmax(probs)\n",
    "- In this paper, they discuss using the weighted average\n",
    "- Example(pretend k= 5)\n",
    "- Possible ratings = [1,2,3,4,5]\n",
    "- Probabilities = [0.05,0.1,0.2,0.5,0.15]\n",
    "- Prediction = $0.05\\cdot 1 + 0.1\\cdot2 + 0.2\\cdot3 + 0.5\\cdot4 + 0.15\\cdot 5 = 3.6$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RBM code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.sparse import lil_matrix, csr_matrix, save_npz, load_npz\n",
    "from datetime import datetime\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- D = input dimensionality = number of movies\n",
    "- K = number of classes = number of possible ratings\n",
    "- M = number of hidden units\n",
    "- N = number of samples = number of users\n",
    "\n",
    "\n",
    "```python\n",
    "def one_hot_encode(X, K):\n",
    "    # input is N x D\n",
    "    # output is N x D x K\n",
    "    N, D = X.shape\n",
    "    Y = np.zeros((N, D, K))\n",
    "    for n, d in zip(*X.nonzero()):\n",
    "        # 0.5...5 --> 1..10 --> 0..9\n",
    "        k = int(X[n,d]*2 - 1)\n",
    "        Y[n,d,k] = 1\n",
    "    return Y\n",
    "\n",
    "- v'(i) * mask\n",
    "    - [1,0,0,0,0]*[1,1,1,1,1] = [1,0,0,0,0]\n",
    "- v'(i) * mask\n",
    "    - [0,0,1,0,0]*[0,0,0,0,0] = [0,0,0,0,0]    \n",
    "\n",
    "def one_hot_mask(X, K):\n",
    "    # input is N x D\n",
    "    # output is N x D x K\n",
    "    N, D = X.shape\n",
    "    Y = np.zeros((N, D, K))\n",
    "    # if X[n,d] == 0, there's a missing rating\n",
    "    # so the mask should be all zeros\n",
    "    # else, it should be all ones\n",
    "    for n, d in zip(*X.nonzero()):\n",
    "        Y[n,d,:] = 1\n",
    "    return Y\n",
    "\n",
    "one_to_ten = np.arange(10) + 1 # [1, 2, 3, ..., 10]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Example(pretend k= 5)\n",
    "- Possible ratings = [1,2,3,4,5]\n",
    "- Probabilities = [0.05,0.1,0.2,0.5,0.15]\n",
    "- Prediction = $0.05\\cdot 1 + 0.1\\cdot2 + 0.2\\cdot3 + 0.5\\cdot4 + 0.15\\cdot 5 = 3.6$\n",
    "\n",
    "```python\n",
    "def convert_probs_to_ratings(probs):\n",
    "    # probs is N x D x K\n",
    "    # output is N x D matrix of predicted ratings\n",
    "    # N, D, K = probs.shape\n",
    "    # out = np.zeros((N, D))\n",
    "    # each predicted rating is a weighted average using the probabilities\n",
    "    # for n in range(N):\n",
    "    #     for d in range(D):\n",
    "    #         out[n,d] = probs[n,d].dot(one_to_ten) / 2\n",
    "    # return out\n",
    "    return probs.dot(one_to_ten) / 2\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$$\n",
    "p(h_{j}=1|v) = \\sigma(\\sum_{k=1}^{K}\\sum_{i=1}^{D}W_{ij}^{k}v_{i}^{k}+c_{j})\\\\\n",
    "p(v_{i}^{k}=1|h) = softmax(\\sum_{j=1}^{M}W_{ij}^{k}h_{j}^{k}+b_{i}^{k})\\\\\n",
    "\\text{where: } softmax(\\alpha_{i}^{k}) = \\frac{exp(\\alpha_{i}^{k})}{\\sum_{k'=1}^{K}exp(\\alpha_{i}^{k'})}\n",
    "$$  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "def dot1(V, W):\n",
    "    # V is N x D x K (batch of visible units)\n",
    "    # W is D x K x M (weights)\n",
    "    # returns N x M (hidden layer size)\n",
    "    return tf.tensordot(V, W, axes=[[1,2], [0,1]])\n",
    "\n",
    "def dot2(H, W):\n",
    "    # H is N x M (batch of hiddens)\n",
    "    # W is D x K x M (weights transposed)\n",
    "    # returns N x D x K (visible)\n",
    "    return tf.tensordot(H, W, axes=[[1], [2]])\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "V : N x \\underline{D} x K  [\\underline{1},2]\\\\\n",
    "W : \\underline{D} x K x M  [\\underline{0},1]\\\\\n",
    "V : N x D x \\underline{K}  [1,\\underline{2}]\\\\\n",
    "W : D x \\underline{K} x M  [0,\\underline{1}]\\\\\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- h = vector of size M\n",
    "- v = 2-D array of size D x K\n",
    "- W = 3-D array of size D x K x M\n",
    "- b = 2-D array of size D x K\n",
    "- c = vector of size M\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "N, M = A.shape\n",
    "rbm = RBM(M, 50, 10)\n",
    "\n",
    "class RBM(object):\n",
    "    def __init__(self, D, M, K):\n",
    "        self.D = D # input feature size\n",
    "        self.M = M # hidden size\n",
    "        self.K = K # number of ratings\n",
    "        self.build(D, M, K)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    def build(self, D, M, K):\n",
    "        # params\n",
    "        self.W = tf.Variable(tf.random_normal(shape=(D, K, M)) * np.sqrt(2.0 / M))\n",
    "        self.c = tf.Variable(np.zeros(M).astype(np.float32))\n",
    "        self.b = tf.Variable(np.zeros((D, K)).astype(np.float32))\n",
    "\n",
    "        # data\n",
    "        self.X_in = tf.placeholder(tf.float32, shape=(None, D, K))\n",
    "        self.mask = tf.placeholder(tf.float32, shape=(None, D, K))\n",
    "```\n",
    "\n",
    "$$\n",
    "p(h_{j}=1|v) = \\sigma(\\sum_{k=1}^{K}\\sum_{i=1}^{D}W_{ij}^{k}v_{i}^{k}+c_{j})\\\\\n",
    "$$  \n",
    "\n",
    "```python\n",
    "        # conditional probabilities\n",
    "        # NOTE: tf.contrib.distributions.Bernoulli API has changed in Tensorflow v1.2\n",
    "        V = self.X_in\n",
    "        p_h_given_v = tf.nn.sigmoid(dot1(V, self.W) + self.c)\n",
    "        self.p_h_given_v = p_h_given_v # save for later\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "```python\n",
    "        # draw a sample from p(h | v)\n",
    "        r = tf.random_uniform(shape=tf.shape(p_h_given_v))\n",
    "        H = tf.to_float(r < p_h_given_v)\n",
    "\n",
    "```\n",
    "\n",
    "$$\n",
    "p(v_{i}^{k}=1|h) = softmax(\\sum_{j=1}^{M}W_{ij}^{k}h_{j}^{k}+b_{i}^{k})\\\\\n",
    "\\text{where: } softmax(\\alpha_{i}^{k}) = \\frac{exp(\\alpha_{i}^{k})}{\\sum_{k'=1}^{K}exp(\\alpha_{i}^{k'})}\n",
    "$$\n",
    "\n",
    "```python\n",
    "        # draw a sample from p(v | h)\n",
    "        # note: we don't have to actually do the softmax\n",
    "        logits = dot2(H, self.W) + self.b\n",
    "        cdist = tf.distributions.Categorical(logits=logits)\n",
    "        X_sample = cdist.sample() # shape is (N, D)\n",
    "        X_sample = tf.one_hot(X_sample, depth=K) # turn it into (N, D, K)\n",
    "        X_sample = X_sample * self.mask # missing ratings shouldn't contribute to objective\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "# build the objective\n",
    "objective = tf.reduce_mean(self.free_energy(self.X_in)) - \n",
    "                        tf.reduce_mean(self.free_energy(X_sample))\n",
    "self.train_op = tf.train.AdamOptimizer(1e-2).minimize(objective)\n",
    "# self.train_op = tf.train.GradientDescentOptimizer(1e-3).minimize(objective)\n",
    "```\n",
    "\n",
    "```python\n",
    "def free_energy(self, V):\n",
    "    first_term = -tf.reduce_sum(dot1(V, self.b))\n",
    "    second_term = -tf.reduce_sum(\n",
    "        # tf.log(1 + tf.exp(tf.matmul(V, self.W) + self.c)),\n",
    "        tf.nn.softplus(dot1(V, self.W) + self.c),\n",
    "        axis=1\n",
    "    )\n",
    "    return first_term + second_term\n",
    "```\n",
    "\n",
    "$$\n",
    "F(v) = -b^{T}v-log\\sum_{h}^{}exp(\\sum_{j=1}^{M}h_{j}u_{j})\\\\\n",
    "F(v) = -b^{T}v-\\sum_{j=1}^{M}log\\bigg\\{ 1+exp(v^{T}W_{:,:,j}+c_{j}) \\bigg\\}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{first term: positive phase :} \\frac{\\partial{F(v)}}{\\partial{\\theta}}\\\\\n",
    "\\text{second term: negative phase :} -\\sum_{v'}^{}p(v')\\frac{\\partial{F(v')}}{\\partial{\\theta}}\n",
    "$$\n",
    "\n",
    "![](https://image.slidesharecdn.com/activationfunction-170608093401/95/activation-function-in-deep-neural-network-17-638.jpg?cb=1496914980)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- forward_logits belows:  \n",
    "\n",
    "$$\n",
    "p(h_{j}=1|v) = \\sigma(\\sum_{k=1}^{K}\\sum_{i=1}^{D}W_{ij}^{k}v_{i}^{k}+c_{j})\\\\\n",
    "\\text{forward_logits} = \\sum_{j=1}^{M}W_{ij}^{k}h_{j}^{k}+b_{i}^{k}\\\\\n",
    "$$\n",
    "\n",
    "\n",
    "```python\n",
    "        # build the cost\n",
    "        # we won't use this to optimize the model parameters\n",
    "        # just to observe what happens during training\n",
    "        logits = self.forward_logits(self.X_in)\n",
    "        self.cost = tf.reduce_mean(\n",
    "            tf.nn.softmax_cross_entropy_with_logits(\n",
    "                labels=self.X_in,\n",
    "                logits=logits,\n",
    "            )\n",
    "        )\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{output_visible} =  p(v_{i}^{k}=1|h) = softmax(\\sum_{j=1}^{M}W_{ij}^{k}h_{j}^{k}+b_{i}^{k})\\\\\n",
    "\\text{where: } softmax(\\alpha_{i}^{k}) = \\frac{exp(\\alpha_{i}^{k})}{\\sum_{k'=1}^{K}exp(\\alpha_{i}^{k'})}\n",
    "$$\n",
    "\n",
    "\n",
    "```python\n",
    "# to get the output\n",
    "        self.output_visible = self.forward_output(self.X_in)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```python\n",
    "for j in range(n_batches):\n",
    "    x = X[j*batch_sz:(j*batch_sz + batch_sz)].toarray()\n",
    "    m = mask[j*batch_sz:(j*batch_sz + batch_sz)].toarray()\n",
    "\n",
    "    # both visible units and mask have to be in one-hot form\n",
    "    # N x D --> N x D x K\n",
    "    batch_one_hot = one_hot_encode(x, self.K)\n",
    "    m = one_hot_mask(m, self.K)\n",
    "\n",
    "    _, c = self.session.run(\n",
    "        (self.train_op, self.cost),\n",
    "        feed_dict={self.X_in: batch_one_hot, self.mask: m}\n",
    "    )\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
