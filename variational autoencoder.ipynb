{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://qph.fs.quoracdn.net/main-qimg-62c793e38456b093cd83fd5476aed596)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian as encoder\n",
    "def gaussian_MLP_encoder(x, n_hidden, n_output, keep_prob):\n",
    "    with tf.variable_scope(\"gaussian_encoder\"):\n",
    "        # initializers\n",
    "        w_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "        b_init = tf.constant_initializer(0.)\n",
    "\n",
    "        # 1st hidden layer\n",
    "        w0 = tf.get_variable('w0', [x.get_shape()[1], n_hidden], initializer=w_init)\n",
    "        b0 = tf.get_variable('b0', [n_hidden], initializer=b_init)\n",
    "        h0 = tf.matmul(x, w0) + b0\n",
    "        h0 = tf.nn.elu(h0)\n",
    "        h0 = tf.nn.dropout(h0, keep_prob)\n",
    "\n",
    "        # 2nd hidden layer\n",
    "        w1 = tf.get_variable('w1', [h0.get_shape()[1], n_hidden], initializer=w_init)\n",
    "        b1 = tf.get_variable('b1', [n_hidden], initializer=b_init)\n",
    "        h1 = tf.matmul(h0, w1) + b1\n",
    "        h1 = tf.nn.tanh(h1)\n",
    "        h1 = tf.nn.dropout(h1, keep_prob)\n",
    "\n",
    "        # output layer                                                                                                                                                                      \n",
    "        # borrowed from https: // github.com / altosaar / vae / blob / master / vae.py\n",
    "        wo = tf.get_variable('wo', [h1.get_shape()[1], n_output * 2], initializer=w_init)\n",
    "        bo = tf.get_variable('bo', [n_output * 2], initializer=b_init)\n",
    "        gaussian_params = tf.matmul(h1, wo) + bo\n",
    "\n",
    "        # The mean parameter is unconstrained\n",
    "        mean = gaussian_params[:, :n_output]\n",
    "        # The standard deviation must be positive. Parametrize with a softplus and\n",
    "        # add a small epsilon for numerical stability\n",
    "        stddev = 1e-6 + tf.nn.softplus(gaussian_params[:, n_output:])\n",
    "\n",
    "    return mean, stddev\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://media.springernature.com/original/springer-static/image/art%3A10.1007%2Fs10115-018-1306-7/MediaObjects/10115_2018_1306_Fig3_HTML.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### decoder\n",
    "- decoder output loss function follows bernoulli distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bernoulli as decoder\n",
    "def bernoulli_decoder(z, n_hidden, n_output, keep_prob, reuse=False):\n",
    "\n",
    "    with tf.variable_scope(\"bernoulli_decoder\", reuse=reuse):\n",
    "        # initializers\n",
    "        w_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "        b_init = tf.constant_initializer(0.)\n",
    "\n",
    "        # 1st hidden layer\n",
    "        w0 = tf.get_variable('w0', [z.get_shape()[1], n_hidden], initializer=w_init)\n",
    "        b0 = tf.get_variable('b0', [n_hidden], initializer=b_init)\n",
    "        h0 = tf.matmul(z, w0) + b0\n",
    "        h0 = tf.nn.tanh(h0)\n",
    "        h0 = tf.nn.dropout(h0, keep_prob)\n",
    "\n",
    "        # 2nd hidden layer\n",
    "        w1 = tf.get_variable('w1', [h0.get_shape()[1], n_hidden], initializer=w_init)\n",
    "        b1 = tf.get_variable('b1', [n_hidden], initializer=b_init)\n",
    "        h1 = tf.matmul(h0, w1) + b1\n",
    "        h1 = tf.nn.elu(h1)\n",
    "        h1 = tf.nn.dropout(h1, keep_prob)\n",
    "\n",
    "        # output layer-mean\n",
    "        wo = tf.get_variable('wo', [h1.get_shape()[1], n_output], initializer=w_init)\n",
    "        bo = tf.get_variable('bo', [n_output], initializer=b_init)\n",
    "        y = tf.sigmoid(tf.matmul(h1, wo) + bo)\n",
    "\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build autoencoder- encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ELBO term\n",
    "![](https://image.slidesharecdn.com/iaf-170120100642/95/improving-variational-inference-with-inverse-autoregressive-flow-2-638.jpg?cb=1484906842)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./pictures/KL_div.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./pictures/reconstruction_error.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./pictures/loss_function1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./pictures/gaussian_loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./pictures/gaussian+bernoulli.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./pictures/gaussian_gaussian.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./pictures/mnist.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencoder(x_hat, x, dim_img, dim_z, n_hidden, keep_prob):\n",
    "\n",
    "    # encoding\n",
    "    mu, sigma = gaussian_encoder(x_hat, n_hidden, dim_z, keep_prob)\n",
    "\n",
    "    # sampling by re-parameterization technique\n",
    "    z = mu + sigma * tf.random_normal(tf.shape(mu), 0, 1, dtype=tf.float32)\n",
    "\n",
    "    # decoding\n",
    "    y = bernoulli_decoder(z, n_hidden, dim_img, keep_prob)\n",
    "    y = tf.clip_by_value(y, 1e-8, 1 - 1e-8)\n",
    "\n",
    "    # loss\n",
    "    marginal_likelihood = tf.reduce_sum(x * tf.log(y) + (1 - x) * tf.log(1 - y), 1)\n",
    "    KL_divergence = 0.5 * tf.reduce_sum(tf.square(mu) + tf.square(sigma) - tf.log(1e-8 + tf.square(sigma)) - 1, 1)\n",
    "\n",
    "    marginal_likelihood = tf.reduce_mean(marginal_likelihood)\n",
    "    KL_divergence = tf.reduce_mean(KL_divergence)\n",
    "\n",
    "    ELBO = marginal_likelihood - KL_divergence\n",
    "\n",
    "    loss = -ELBO\n",
    "\n",
    "    return y, z, loss, -marginal_likelihood, KL_divergence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def decoder(z, dim_img, n_hidden):\n",
    "\n",
    "    y = bernoulli_decoder(z, n_hidden, dim_img, 1.0, reuse=True)\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### references\n",
    "variational autoencoder from https://github.com/hwalsuklee/tensorflow-mnist-VAE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
