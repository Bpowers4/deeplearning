{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional RNN  \n",
    "![](https://cn.bing.com/th?id=OIP.tZtg4-7QAkaUdPyBbNBlXwHaEt&pid=Api&rs=1&p=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- if each RNN unit's latent dimension is M, \\begin{equation*}h_t\\end{equation*} should be of size 2M\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Many-to-One Problem\n",
    "- The backward RNN has only seen one last word!\n",
    "\n",
    "\\begin{equation*}\n",
    "out = [\\vec{h_T}, \\overleftarrow{h_1}] \\\\\n",
    "\\end{equation*}\n",
    "\n",
    "- This is default behavior in Keras if return_sequence= False\n",
    "\n",
    "- Another solution \n",
    "    - take the max over all hidden states\n",
    "\\begin{equation*}\n",
    "out = \\max_{t}  h_t\\\\\n",
    "\\end{equation*}\n",
    "    - What if we took the softmax instead of max? keep this in mind for Attention\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When not to use a Bidirectional RNN\n",
    "- not to use for predicting the future\n",
    "- it doesn't make sense for inputs to come from even further in the future\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, GRU, Bidirectional\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras.backend as K\n",
    "if len(K.tensorflow_backend._get_available_gpus()) > 0:\n",
    "    from keras.layers import CuDNNLSTM as LSTM\n",
    "    from keras.layers import CuDNNGRU as GRU\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 8, 20)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = 8\n",
    "D = 20\n",
    "M = 3\n",
    "\n",
    "X = np.random.randn(1, T, D)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.59215575, -0.99875615, -0.80206125,  0.50841239,\n",
       "         -0.1559104 ,  1.02235294,  0.49800112, -0.56908889,\n",
       "         -0.34025952, -0.53371617,  0.00286114,  1.43003495,\n",
       "          1.52893131,  0.28340541, -1.34811457, -1.46465738,\n",
       "         -1.03972654, -1.24180737, -0.37111895,  1.05344886],\n",
       "        [-0.45782456, -0.74904535,  1.66153361,  0.05113275,\n",
       "          2.77182987, -1.2462556 ,  1.19900642, -0.15166592,\n",
       "         -1.14872252, -2.18543846,  0.89098527,  0.08289235,\n",
       "          0.3848108 , -0.00658806, -2.48954578,  2.61407273,\n",
       "         -1.1011952 , -0.80532234, -1.0876434 , -0.47016428],\n",
       "        [-0.88635914,  0.11020603, -0.10451324, -0.61823208,\n",
       "          0.17984517,  0.1392936 , -0.2425376 , -0.34382657,\n",
       "          0.31293554, -0.47095947,  0.71068175, -0.45563558,\n",
       "         -0.8569422 ,  1.36839485, -0.80173691,  2.03356689,\n",
       "         -2.14952568,  0.31888211,  0.38215729, -0.15716281],\n",
       "        [-0.32067256, -0.76889461, -0.04986577, -1.60472858,\n",
       "          0.62292881, -0.36411297,  0.84910118,  0.80598987,\n",
       "          1.48980909,  0.67408736, -0.14087816,  0.32606845,\n",
       "          1.17041108, -0.83290208,  1.1464286 , -0.53158636,\n",
       "         -1.7145472 ,  0.91644941,  0.38667043, -1.66830499],\n",
       "        [ 1.73439716, -1.86160547,  0.80202921, -0.28278866,\n",
       "         -0.82931695,  0.0843804 , -0.28774883, -1.28556904,\n",
       "         -0.14493579,  0.22535911, -0.57569472,  2.09635091,\n",
       "          0.36315802,  0.44196472,  1.29041156, -0.72714954,\n",
       "         -1.11453398, -1.68929388, -0.13433091,  0.22847366],\n",
       "        [-0.47079375, -0.01815654,  0.56821783,  0.29758761,\n",
       "          0.14233784,  0.97457131,  0.4760985 , -0.25398585,\n",
       "         -0.2299024 , -0.3300033 ,  1.60154341, -0.34688752,\n",
       "          1.19052938,  1.16634096, -0.84093849, -0.39591433,\n",
       "          0.24342389, -0.13938812, -0.25279434,  0.45757261],\n",
       "        [-0.32148981, -0.91023239, -0.00788265, -1.07034334,\n",
       "          1.20278088,  0.16685393,  0.21404192,  0.13029964,\n",
       "         -0.74561958,  0.7810509 ,  0.27861185,  2.03740612,\n",
       "          0.76143928,  0.27349289, -2.22879963, -1.1563172 ,\n",
       "         -0.13740118,  0.21972398, -0.83533635, -2.06214765],\n",
       "        [-0.23782454,  0.68756217,  0.23691047,  0.03427796,\n",
       "          0.2699151 ,  0.34132058,  0.5809599 , -0.0502504 ,\n",
       "         -1.29140627, -0.07170843,  0.6035735 ,  1.0042692 ,\n",
       "         -1.49945793,  1.26735226, -0.65374173, -2.3287486 ,\n",
       "         -0.84636899,  1.09800515,  0.68133481, -1.73758627]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = Input(shape=(T, D))\n",
    "rnn = Bidirectional(LSTM(M, return_state=True, return_sequences=True))\n",
    "# rnn = Bidirectional(LSTM(M, return_state=True, return_sequences=False))\n",
    "x = rnn(input_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o: [[[ 0.18119621  0.01583676  0.20686583  0.21239105 -0.05004329\n",
      "   -0.05696144]\n",
      "  [ 0.02418935  0.05985089  0.18329658 -0.0693098  -0.16771546\n",
      "   -0.2273484 ]\n",
      "  [ 0.06540236  0.19442108  0.2990017  -0.00376892 -0.2814624\n",
      "   -0.24852385]\n",
      "  [-0.06846699  0.14171138  0.32254672  0.09992275 -0.06165175\n",
      "   -0.13075766]\n",
      "  [-0.15302575  0.19428375  0.0460598   0.15211043 -0.03509453\n",
      "    0.15433581]\n",
      "  [-0.08738933  0.063574    0.2251744   0.16290708 -0.02215824\n",
      "   -0.08731462]\n",
      "  [-0.13260986  0.25557363  0.10454654  0.12669256  0.02675493\n",
      "   -0.05862847]\n",
      "  [-0.04098389  0.45581076  0.02110858  0.00144373 -0.13307135\n",
      "   -0.04553765]]]\n",
      "o.shape: (1, 8, 6)\n",
      "h1: [[-0.04098389  0.45581076  0.02110858]]\n",
      "c1: [[-0.456286    0.88852847  0.6460419 ]]\n",
      "h2: [[ 0.21239105 -0.05004329 -0.05696144]]\n",
      "c2: [[ 0.41276407 -0.5533985  -0.11868316]]\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=input_, outputs=x)\n",
    "o, h1, c1, h2, c2 = model.predict(X)\n",
    "print(\"o:\", o)\n",
    "print(\"o.shape:\", o.shape)\n",
    "print(\"h1:\", h1)\n",
    "print(\"c1:\", c1)\n",
    "print(\"h2:\", h2)\n",
    "print(\"c2:\", c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o: [[ 0.24157766  0.07058255 -0.4550641   0.00260599  0.09559534 -0.20733805]]\n",
      "o.shape: (1, 6)\n",
      "h1: [[ 0.24157766  0.07058255 -0.4550641 ]]\n",
      "c1: [[ 0.47180873  0.14923403 -0.9594811 ]]\n",
      "h2: [[ 0.00260599  0.09559534 -0.20733805]]\n",
      "c2: [[ 0.66224265  0.2606456  -0.3786462 ]]\n"
     ]
    }
   ],
   "source": [
    "input_ = Input(shape=(T, D))\n",
    "# rnn = Bidirectional(LSTM(M, return_state=True, return_sequences=True))\n",
    "rnn = Bidirectional(LSTM(M, return_state=True, return_sequences=False))\n",
    "x = rnn(input_)\n",
    "model = Model(inputs=input_, outputs=x)\n",
    "o, h1, c1, h2, c2 = model.predict(X)\n",
    "print(\"o:\", o)\n",
    "print(\"o.shape:\", o.shape)\n",
    "print(\"h1:\", h1)\n",
    "print(\"c1:\", c1)\n",
    "print(\"h2:\", h2)\n",
    "print(\"c2:\", c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         (None, 8, 20)             0         \n",
      "_________________________________________________________________\n",
      "bidirectional_8 (Bidirection [(None, 6), (None, 3), (N 576       \n",
      "=================================================================\n",
      "Total params: 576\n",
      "Trainable params: 576\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'bidirectional_1/forward_lstm_1/kernel:0' shape=(2, 12) dtype=float32_ref>,\n",
       " <tf.Variable 'bidirectional_1/forward_lstm_1/recurrent_kernel:0' shape=(3, 12) dtype=float32_ref>,\n",
       " <tf.Variable 'bidirectional_1/forward_lstm_1/bias:0' shape=(12,) dtype=float32_ref>,\n",
       " <tf.Variable 'bidirectional_1/backward_lstm_1/kernel:0' shape=(2, 12) dtype=float32_ref>,\n",
       " <tf.Variable 'bidirectional_1/backward_lstm_1/recurrent_kernel:0' shape=(3, 12) dtype=float32_ref>,\n",
       " <tf.Variable 'bidirectional_1/backward_lstm_1/bias:0' shape=(12,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### toxic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Embedding, Input\n",
    "from keras.layers import LSTM, Bidirectional, GlobalMaxPool1D, Dropout\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import keras.backend as K\n",
    "if len(K.tensorflow_backend._get_available_gpus()) > 0:\n",
    "    from keras.layers import CuDNNLSTM as LSTM\n",
    "    from keras.layers import CuDNNGRU as GRU\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some configuration\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "MAX_VOCAB_SIZE = 20000\n",
    "EMBEDDING_DIM = 50\n",
    "VALIDATION_SPLIT = 0.2\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in pre-trained word vectors\n",
    "word2vec = {}\n",
    "with open(os.path.join('../large_files/glove.6B/glove.6B.%sd.txt' % EMBEDDING_DIM)) as f:\n",
    "  # is just a space-separated text file in the format:\n",
    "  # word vec[0] vec[1] vec[2] ...\n",
    "  for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    vec = np.asarray(values[1:], dtype='float32')\n",
    "    word2vec[word] = vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../large_files/toxic-comment/train.csv\")\n",
    "sentences = train[\"comment_text\"].fillna(\"DUMMY_VALUE\").values\n",
    "possible_labels = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "targets = train[possible_labels].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the sentences (strings) into integers\n",
    "tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "sequences = tokenizer.texts_to_sequences(sentences)\n",
    "\n",
    "# get word -> integer mapping\n",
    "word2idx = tokenizer.word_index\n",
    "\n",
    "# pad sequences so that we get a N x T matrix\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare embedding matrix\n",
    "num_words = min(MAX_VOCAB_SIZE, len(word2idx) + 1)\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word2idx.items():\n",
    "  if i < MAX_VOCAB_SIZE:\n",
    "    embedding_vector = word2vec.get(word)\n",
    "    if embedding_vector is not None:\n",
    "      # words not found in embedding index will be all zeros.\n",
    "      embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained word embeddings into an Embedding layer\n",
    "# note that we set trainable = False so as to keep the embeddings fixed\n",
    "\n",
    "# temp code for compile\n",
    "num_words = MAX_VOCAB_SIZE\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "possible_labels = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "\n",
    "embedding_layer = Embedding(\n",
    "  num_words,\n",
    "  EMBEDDING_DIM,\n",
    "  weights=[embedding_matrix],\n",
    "  input_length=MAX_SEQUENCE_LENGTH,\n",
    "  trainable=False\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n"
     ]
    }
   ],
   "source": [
    "print('Building model...')\n",
    "\n",
    "# create an LSTM network with a single LSTM\n",
    "input_ = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
    "x = embedding_layer(input_)\n",
    "# x = LSTM(15, return_sequences=True)(x)\n",
    "x = Bidirectional(LSTM(15, return_sequences=True))(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "output = Dense(len(possible_labels), activation=\"sigmoid\")(x)\n",
    "\n",
    "model = Model(input_, output)\n",
    "model.compile(\n",
    "  loss='binary_crossentropy',\n",
    "  optimizer=Adam(lr=0.01),\n",
    "  metrics=['accuracy']\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 100, 50)           1000000   \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 100, 30)           7920      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 186       \n",
      "=================================================================\n",
      "Total params: 1,008,106\n",
      "Trainable params: 8,106\n",
      "Non-trainable params: 1,000,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training model...')\n",
    "r = model.fit(\n",
    "  data,\n",
    "  targets,\n",
    "  batch_size=BATCH_SIZE,\n",
    "  epochs=EPOCHS,\n",
    "  validation_split=VALIDATION_SPLIT\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Classification with Bidirectional RNNs\n",
    "- RNNs can be used for images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- An image as a sequence of pixels\n",
    "\n",
    "#### Architecture\n",
    "- Let's pretend the image is a sequence of word vectors( T x D matrix)\n",
    "- Pretend height = T , width = D\n",
    "- Rotate the image and run a Bidirectional RNN on both, we go in all 4 directions\n",
    "\n",
    "[tensorflow example](http://easy-tensorflow.com/tf-tutorials/recurrent-neural-networks/bidirectional-rnn-for-classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- given LSTM latent dimensionality  = M, what is the output size?\n",
    "- input (N x H x W) -> bi-LSTM(N x H x 2M) -> maxpool -> N x 2M\n",
    "- rotate (N x H x W) -> bi-LSTM(N x H x 2M) -> maxpool -> N x 2M\n",
    "- concat output ( N x 4M)\n",
    "- Dense + softmax to get prediction ( N x K)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get data\n",
    "X, Y = get_mnist()\n",
    "\n",
    "# config\n",
    "D = 28\n",
    "M = 15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# input is an image of size 28x28\n",
    "input_ = Input(shape=(D, D))\n",
    "\n",
    "# up-down\n",
    "rnn1 = Bidirectional(LSTM(M, return_sequences=True))\n",
    "x1 = rnn1(input_) # output is N x D x 2M\n",
    "x1 = GlobalMaxPooling1D()(x1) # output is N x 2M\n",
    "\n",
    "# left-right\n",
    "rnn2 = Bidirectional(LSTM(M, return_sequences=True))\n",
    "\n",
    "# custom layer\n",
    "permutor = Lambda(lambda t: K.permute_dimensions(t, pattern=(0, 2, 1)))\n",
    "\n",
    "x2 = permutor(input_)\n",
    "x2 = rnn2(x2) # output is N x D x 2M\n",
    "x2 = GlobalMaxPooling1D()(x2) # output is N x 2M\n",
    "\n",
    "# put them together\n",
    "concatenator = Concatenate(axis=1)\n",
    "x = concatenator([x1, x2]) # output is N x 4M\n",
    "\n",
    "# final dense layer\n",
    "output = Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=input_, outputs=output)\n",
    "\n",
    "# testing\n",
    "# o = model.predict(X)\n",
    "# print(\"o.shape:\", o.shape)\n",
    "\n",
    "# compile\n",
    "model.compile(\n",
    "  loss='sparse_categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# train\n",
    "print('Training model...')\n",
    "r = model.fit(X, Y, batch_size=32, epochs=10, validation_split=0.3)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
