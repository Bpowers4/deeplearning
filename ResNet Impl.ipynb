{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convblock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def init_filter(d, mi, mo, stride):\n",
    "  return (np.random.randn(d, d, mi, mo) * np.sqrt(2.0 / (d * d * mi))).astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer:\n",
    "  def __init__(self, d, mi, mo, stride=2, padding='VALID'):\n",
    "    self.W = tf.Variable(init_filter(d, mi, mo, stride))\n",
    "    self.b = tf.Variable(np.zeros(mo, dtype=np.float32))\n",
    "    self.stride = stride\n",
    "    self.padding = padding\n",
    "\n",
    "  def forward(self, X):\n",
    "    X = tf.nn.conv2d(\n",
    "      X,\n",
    "      self.W,\n",
    "      strides=[1, self.stride, self.stride, 1],\n",
    "      padding=self.padding\n",
    "    )\n",
    "    X = X + self.b\n",
    "    return X\n",
    "\n",
    "  def copyFromKerasLayers(self, layer):\n",
    "    # only 1 layer to copy from\n",
    "    W, b = layer.get_weights()\n",
    "    op1 = self.W.assign(W)\n",
    "    op2 = self.b.assign(b)\n",
    "    self.session.run((op1, op2))\n",
    "\n",
    "  # def copyFromWeights(self, W, b):\n",
    "  #   op1 = self.W.assign(W)\n",
    "  #   op2 = self.b.assign(b)\n",
    "  #   self.session.run((op1, op2))\n",
    "\n",
    "  def get_params(self):\n",
    "    return [self.W, self.b]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNormLayer:\n",
    "  def __init__(self, D):\n",
    "    self.running_mean = tf.Variable(np.zeros(D, dtype=np.float32), trainable=False)\n",
    "    self.running_var  = tf.Variable(np.ones(D, dtype=np.float32), trainable=False)\n",
    "    self.gamma        = tf.Variable(np.ones(D, dtype=np.float32))\n",
    "    self.beta         = tf.Variable(np.zeros(D, dtype=np.float32))\n",
    "\n",
    "  def forward(self, X):\n",
    "    return tf.nn.batch_normalization(\n",
    "      X,\n",
    "      self.running_mean,\n",
    "      self.running_var,\n",
    "      self.beta,\n",
    "      self.gamma,\n",
    "      1e-3\n",
    "    )\n",
    "\n",
    "  def copyFromKerasLayers(self, layer):\n",
    "    # only 1 layer to copy from\n",
    "    # order:\n",
    "    # gamma, beta, moving mean, moving variance\n",
    "    gamma, beta, running_mean, running_var = layer.get_weights()\n",
    "    op1 = self.running_mean.assign(running_mean)\n",
    "    op2 = self.running_var.assign(running_var)\n",
    "    op3 = self.gamma.assign(gamma)\n",
    "    op4 = self.beta.assign(beta)\n",
    "    self.session.run((op1, op2, op3, op4))\n",
    "\n",
    "  def get_params(self):\n",
    "    return [self.running_mean, self.running_var, self.gamma, self.beta]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ConvBlock:\n",
    "  def __init__(self, mi, fm_sizes, stride=2, activation=tf.nn.relu):\n",
    "    # conv1, conv2, conv3\n",
    "    # note: # feature maps shortcut = # feauture maps conv 3\n",
    "    assert(len(fm_sizes) == 3)\n",
    "\n",
    "    # note: kernel size in 2nd conv is always 3\n",
    "    #       so we won't bother including it as an arg\n",
    "\n",
    "    # note: stride only applies to conv 1 in main branch\n",
    "    #       and conv in shortcut, otherwise stride is 1\n",
    "\n",
    "    self.session = None\n",
    "    self.f = tf.nn.relu\n",
    "    \n",
    "    # init main branch\n",
    "    # Conv -> BN -> F() ---> Conv -> BN -> F() ---> Conv -> BN\n",
    "    self.conv1 = ConvLayer(1, mi, fm_sizes[0], stride)\n",
    "    self.bn1   = BatchNormLayer(fm_sizes[0])\n",
    "    self.conv2 = ConvLayer(3, fm_sizes[0], fm_sizes[1], 1, 'SAME')\n",
    "    self.bn2   = BatchNormLayer(fm_sizes[1])\n",
    "    self.conv3 = ConvLayer(1, fm_sizes[1], fm_sizes[2], 1)\n",
    "    self.bn3   = BatchNormLayer(fm_sizes[2])\n",
    "\n",
    "    # init shortcut branch\n",
    "    # Conv -> BN\n",
    "    self.convs = ConvLayer(1, mi, fm_sizes[2], stride)\n",
    "    self.bns   = BatchNormLayer(fm_sizes[2])\n",
    "\n",
    "    # in case needed later\n",
    "    self.layers = [\n",
    "      self.conv1, self.bn1,\n",
    "      self.conv2, self.bn2,\n",
    "      self.conv3, self.bn3,\n",
    "      self.convs, self.bns\n",
    "    ]\n",
    "\n",
    "    # this will not be used when input passed in from\n",
    "    # a previous layer\n",
    "    self.input_ = tf.placeholder(tf.float32, shape=(1, 224, 224, mi))\n",
    "    self.output = self.forward(self.input_)\n",
    "\n",
    "  def forward(self, X):\n",
    "    # main branch\n",
    "    FX = self.conv1.forward(X)\n",
    "    FX = self.bn1.forward(FX)\n",
    "    FX = self.f(FX)\n",
    "    FX = self.conv2.forward(FX)\n",
    "    FX = self.bn2.forward(FX)\n",
    "    FX = self.f(FX)\n",
    "    FX = self.conv3.forward(FX)\n",
    "    FX = self.bn3.forward(FX)\n",
    "\n",
    "    # shortcut branch\n",
    "    SX = self.convs.forward(X)\n",
    "    SX = self.bns.forward(SX)\n",
    "\n",
    "    return self.f(FX + SX)\n",
    "\n",
    "  def predict(self, X):\n",
    "    assert(self.session is not None)\n",
    "    return self.session.run(\n",
    "      self.output,\n",
    "      feed_dict={self.input_: X}\n",
    "    )\n",
    "\n",
    "  def set_session(self, session):\n",
    "    # need to make this a session\n",
    "    # so assignment happens on sublayers too\n",
    "    self.session = session\n",
    "    self.conv1.session = session\n",
    "    self.bn1.session = session\n",
    "    self.conv2.session = session\n",
    "    self.bn2.session = session\n",
    "    self.conv3.session = session\n",
    "    self.bn3.session = session\n",
    "    self.convs.session = session\n",
    "    self.bns.session = session\n",
    "\n",
    "  def copyFromKerasLayers(self, layers):\n",
    "    # [<keras.layers.convolutional.Conv2D at 0x117bd1978>,\n",
    "    #  <keras.layers.normalization.BatchNormalization at 0x117bf84a8>,\n",
    "    #  <keras.layers.core.Activation at 0x117c15fd0>,\n",
    "    #  <keras.layers.convolutional.Conv2D at 0x117c23be0>,\n",
    "    #  <keras.layers.normalization.BatchNormalization at 0x117c51978>,\n",
    "    #  <keras.layers.core.Activation at 0x117c93518>,\n",
    "    #  <keras.layers.convolutional.Conv2D at 0x117cc1518>,\n",
    "    #  <keras.layers.convolutional.Conv2D at 0x117d21630>,\n",
    "    #  <keras.layers.normalization.BatchNormalization at 0x117cd2a58>,\n",
    "    #  <keras.layers.normalization.BatchNormalization at 0x117d44b00>,\n",
    "    #  <keras.layers.merge.Add at 0x117dae748>,\n",
    "    #  <keras.layers.core.Activation at 0x117da2eb8>]\n",
    "    self.conv1.copyFromKerasLayers(layers[0])\n",
    "    self.bn1.copyFromKerasLayers(layers[1])\n",
    "    self.conv2.copyFromKerasLayers(layers[3])\n",
    "    self.bn2.copyFromKerasLayers(layers[4])\n",
    "    self.conv3.copyFromKerasLayers(layers[6])\n",
    "    self.bn3.copyFromKerasLayers(layers[8])\n",
    "    self.convs.copyFromKerasLayers(layers[7])\n",
    "    self.bns.copyFromKerasLayers(layers[9])\n",
    "\n",
    "  def get_params(self):\n",
    "    params = []\n",
    "    for layer in self.layers:\n",
    "      params += layer.get_params()\n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output.shape: (1, 224, 224, 256)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "  conv_block = ConvBlock(mi=3, fm_sizes=[64, 64, 256], stride=1)\n",
    "\n",
    "  # make a fake image\n",
    "  X = np.random.random((1, 224, 224, 3))\n",
    "\n",
    "  init = tf.global_variables_initializer()\n",
    "  with tf.Session() as session:\n",
    "    conv_block.set_session(session)\n",
    "    session.run(init)\n",
    "\n",
    "    output = conv_block.predict(X)\n",
    "    print(\"output.shape:\", output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[9.98377323e-01, 1.18946671e+00, 6.80550575e-01, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 1.74632192e+00],\n",
       "         [1.71091628e+00, 1.18397129e+00, 1.86851668e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [6.18836582e-01, 3.99079740e-01, 6.40911937e-01, ...,\n",
       "          4.06729460e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "         ...,\n",
       "         [1.47901881e+00, 1.27081215e+00, 1.80087328e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 6.24309063e-01],\n",
       "         [7.42667079e-01, 2.63923526e-01, 8.39986444e-01, ...,\n",
       "          2.42179096e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "         [4.36642841e-02, 5.63806593e-02, 3.51840397e-03, ...,\n",
       "          4.41147029e-01, 3.50591421e-01, 0.00000000e+00]],\n",
       "\n",
       "        [[2.87527514e+00, 3.90360773e-01, 1.89426565e+00, ...,\n",
       "          2.93770432e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "         [2.54572940e+00, 6.85984492e-01, 2.14225197e+00, ...,\n",
       "          0.00000000e+00, 4.43948627e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 1.28919435e+00, 4.82443184e-01, ...,\n",
       "          7.23397017e-01, 2.65187025e-03, 6.22696221e-01],\n",
       "         ...,\n",
       "         [5.18080592e-01, 2.69447565e-02, 0.00000000e+00, ...,\n",
       "          3.56961727e-01, 0.00000000e+00, 1.79077208e-01],\n",
       "         [1.08637094e+00, 8.60905290e-01, 5.63560128e-01, ...,\n",
       "          3.16820681e-01, 0.00000000e+00, 6.37633562e-01],\n",
       "         [0.00000000e+00, 1.01527023e+00, 0.00000000e+00, ...,\n",
       "          6.13809168e-01, 3.20634574e-01, 1.22163892e+00]],\n",
       "\n",
       "        [[1.24085760e+00, 9.14727986e-01, 0.00000000e+00, ...,\n",
       "          1.58652067e-02, 0.00000000e+00, 1.03174293e+00],\n",
       "         [1.66841650e+00, 3.96689236e-01, 5.98668993e-01, ...,\n",
       "          7.40260184e-01, 1.12573281e-01, 0.00000000e+00],\n",
       "         [6.96251035e-01, 3.33872795e-01, 2.89831460e-02, ...,\n",
       "          1.03838038e+00, 4.87844557e-01, 0.00000000e+00],\n",
       "         ...,\n",
       "         [4.20468628e-01, 4.15741742e-01, 8.21585879e-02, ...,\n",
       "          1.05465996e+00, 1.23853564e-01, 0.00000000e+00],\n",
       "         [8.01597476e-01, 1.14780068e+00, 0.00000000e+00, ...,\n",
       "          8.85433197e-01, 2.08864063e-01, 1.49429977e-01],\n",
       "         [1.00240457e+00, 1.12729883e+00, 2.92227268e-01, ...,\n",
       "          9.21745121e-01, 3.74276042e-02, 5.66969573e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[9.89222586e-01, 6.95957541e-01, 0.00000000e+00, ...,\n",
       "          7.78781295e-01, 0.00000000e+00, 8.37575972e-01],\n",
       "         [1.15117347e+00, 7.11968899e-01, 0.00000000e+00, ...,\n",
       "          1.29869342e+00, 1.67499810e-01, 0.00000000e+00],\n",
       "         [1.61629260e+00, 1.55138266e+00, 1.10396016e+00, ...,\n",
       "          1.25933886e-02, 0.00000000e+00, 4.00384784e-01],\n",
       "         ...,\n",
       "         [3.04859132e-02, 4.14941877e-01, 0.00000000e+00, ...,\n",
       "          1.17052460e+00, 3.63274992e-01, 1.15664899e-01],\n",
       "         [1.51187539e+00, 1.44061708e+00, 2.39679515e-01, ...,\n",
       "          2.57007480e-01, 0.00000000e+00, 1.59293199e+00],\n",
       "         [1.66828603e-01, 9.27941144e-01, 0.00000000e+00, ...,\n",
       "          2.78003603e-01, 0.00000000e+00, 1.28146434e+00]],\n",
       "\n",
       "        [[7.51658916e-01, 1.49362254e+00, 0.00000000e+00, ...,\n",
       "          3.95401120e-01, 0.00000000e+00, 1.54531050e+00],\n",
       "         [5.87057889e-01, 8.32417607e-01, 0.00000000e+00, ...,\n",
       "          1.68045366e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [1.78621602e+00, 1.11924911e+00, 1.93057179e+00, ...,\n",
       "          1.07125747e+00, 1.02298141e-01, 0.00000000e+00],\n",
       "         ...,\n",
       "         [3.56376648e-01, 4.28307354e-01, 4.56014276e-02, ...,\n",
       "          1.35534465e+00, 6.54007673e-01, 0.00000000e+00],\n",
       "         [1.76972187e+00, 1.13779068e-01, 1.04509497e+00, ...,\n",
       "          4.92898345e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "         [5.72023034e-01, 8.79088879e-01, 0.00000000e+00, ...,\n",
       "          3.04472923e-01, 0.00000000e+00, 1.10197580e+00]],\n",
       "\n",
       "        [[1.17228484e+00, 9.28928614e-01, 0.00000000e+00, ...,\n",
       "          4.08331990e-01, 0.00000000e+00, 1.04614353e+00],\n",
       "         [1.91867578e+00, 1.16929889e+00, 9.62797701e-01, ...,\n",
       "          9.56041813e-02, 0.00000000e+00, 1.45989895e+00],\n",
       "         [2.07358336e+00, 3.03460896e-01, 1.52624345e+00, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 3.11603725e-01],\n",
       "         ...,\n",
       "         [9.90129471e-01, 9.84445989e-01, 3.87429833e-01, ...,\n",
       "          7.10225344e-01, 0.00000000e+00, 1.34646356e+00],\n",
       "         [2.62469769e-01, 6.83438540e-01, 1.05010390e-01, ...,\n",
       "          1.15190303e+00, 1.90881073e-01, 0.00000000e+00],\n",
       "         [1.18589449e+00, 9.33098912e-01, 3.59432876e-01, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 1.38083744e+00]]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class IdentityBlock:\n",
    "  def __init__(self, mi, fm_sizes, activation=tf.nn.relu):\n",
    "    # conv1, conv2, conv3\n",
    "    # note: # feature maps shortcut = # feauture maps conv 3\n",
    "    assert(len(fm_sizes) == 3)\n",
    "\n",
    "    # note: kernel size in 2nd conv is always 3\n",
    "    #       so we won't bother including it as an arg\n",
    "\n",
    "    self.session = None\n",
    "    self.f = tf.nn.relu\n",
    "    \n",
    "    # init main branch\n",
    "    # Conv -> BN -> F() ---> Conv -> BN -> F() ---> Conv -> BN\n",
    "    self.conv1 = ConvLayer(1, mi, fm_sizes[0], 1)\n",
    "    self.bn1   = BatchNormLayer(fm_sizes[0])\n",
    "    self.conv2 = ConvLayer(3, fm_sizes[0], fm_sizes[1], 1, 'SAME')\n",
    "    self.bn2   = BatchNormLayer(fm_sizes[1])\n",
    "    self.conv3 = ConvLayer(1, fm_sizes[1], fm_sizes[2], 1)\n",
    "    self.bn3   = BatchNormLayer(fm_sizes[2])\n",
    "\n",
    "    # in case needed later\n",
    "    self.layers = [\n",
    "      self.conv1, self.bn1,\n",
    "      self.conv2, self.bn2,\n",
    "      self.conv3, self.bn3,\n",
    "    ]\n",
    "\n",
    "    # this will not be used when input passed in from\n",
    "    # a previous layer\n",
    "    self.input_ = tf.placeholder(tf.float32, shape=(1, 224, 224, mi))\n",
    "    self.output = self.forward(self.input_)\n",
    "\n",
    "  def forward(self, X):\n",
    "    # main branch\n",
    "    FX = self.conv1.forward(X)\n",
    "    FX = self.bn1.forward(FX)\n",
    "    FX = self.f(FX)\n",
    "    FX = self.conv2.forward(FX)\n",
    "    FX = self.bn2.forward(FX)\n",
    "    FX = self.f(FX)\n",
    "    FX = self.conv3.forward(FX)\n",
    "    FX = self.bn3.forward(FX)\n",
    "\n",
    "    return self.f(FX + X)\n",
    "\n",
    "  def predict(self, X):\n",
    "    assert(self.session is not None)\n",
    "    return self.session.run(\n",
    "      self.output,\n",
    "      feed_dict={self.input_: X}\n",
    "    )\n",
    "\n",
    "  def set_session(self, session):\n",
    "    # need to make this a session\n",
    "    # so assignment happens on sublayers too\n",
    "    self.session = session\n",
    "    self.conv1.session = session\n",
    "    self.bn1.session = session\n",
    "    self.conv2.session = session\n",
    "    self.bn2.session = session\n",
    "    self.conv3.session = session\n",
    "    self.bn3.session = session\n",
    "\n",
    "  def copyFromKerasLayers(self, layers):\n",
    "    assert(len(layers) == 10)\n",
    "    # <keras.layers.convolutional.Conv2D at 0x7fa44255ff28>,\n",
    "    # <keras.layers.normalization.BatchNormalization at 0x7fa44250e7b8>,\n",
    "    # <keras.layers.core.Activation at 0x7fa44252d9e8>,\n",
    "    # <keras.layers.convolutional.Conv2D at 0x7fa44253af60>,\n",
    "    # <keras.layers.normalization.BatchNormalization at 0x7fa4424e4f60>,\n",
    "    # <keras.layers.core.Activation at 0x7fa442494828>,\n",
    "    # <keras.layers.convolutional.Conv2D at 0x7fa4424a2da0>,\n",
    "    # <keras.layers.normalization.BatchNormalization at 0x7fa44244eda0>,\n",
    "    # <keras.layers.merge.Add at 0x7fa44245d5c0>,\n",
    "    # <keras.layers.core.Activation at 0x7fa44240aba8>\n",
    "    self.conv1.copyFromKerasLayers(layers[0])\n",
    "    self.bn1.copyFromKerasLayers(layers[1])\n",
    "    self.conv2.copyFromKerasLayers(layers[3])\n",
    "    self.bn2.copyFromKerasLayers(layers[4])\n",
    "    self.conv3.copyFromKerasLayers(layers[6])\n",
    "    self.bn3.copyFromKerasLayers(layers[7])\n",
    "\n",
    "  def get_params(self):\n",
    "    params = []\n",
    "    for layer in self.layers:\n",
    "      params += layer.get_params()\n",
    "    return params\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output.shape: (1, 224, 224, 256)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "  identity_block = IdentityBlock(mi=256, fm_sizes=[64, 64, 256])\n",
    "\n",
    "  # make a fake image\n",
    "  X = np.random.random((1, 224, 224, 256))\n",
    "\n",
    "  init = tf.global_variables_initializer()\n",
    "  with tf.Session() as session:\n",
    "    identity_block.set_session(session)\n",
    "    session.run(init)\n",
    "\n",
    "    output = identity_block.predict(X)\n",
    "    print(\"output.shape:\", output.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 50 layers ResNet Impl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://postfiles.pstatic.net/20160718_2/laonple_1468811199171uLSM4_PNG/%C0%CC%B9%CC%C1%F6_80.png?type=w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFResNet:\n",
    "  def __init__(self):\n",
    "    self.layers = [\n",
    "      # before conv block\n",
    "      ConvLayer(d=7, mi=3, mo=64, stride=2, padding='SAME'),\n",
    "      BatchNormLayer(64),\n",
    "      ReLULayer(),\n",
    "      MaxPoolLayer(dim=3),\n",
    "      # conv block\n",
    "      ConvBlock(mi=64, fm_sizes=[64, 64, 256], stride=1),\n",
    "      # identity block x 2\n",
    "      IdentityBlock(mi=256, fm_sizes=[64, 64, 256]),\n",
    "      IdentityBlock(mi=256, fm_sizes=[64, 64, 256]),\n",
    "      # conv block\n",
    "      ConvBlock(mi=256, fm_sizes=[128, 128, 512], stride=2),\n",
    "      # identity block x 3\n",
    "      IdentityBlock(mi=512, fm_sizes=[128, 128, 512]),\n",
    "      IdentityBlock(mi=512, fm_sizes=[128, 128, 512]),\n",
    "      IdentityBlock(mi=512, fm_sizes=[128, 128, 512]),\n",
    "      # conv block\n",
    "      ConvBlock(mi=512, fm_sizes=[256, 256, 1024], stride=2),\n",
    "      # identity block x 5\n",
    "      IdentityBlock(mi=1024, fm_sizes=[256, 256, 1024]),\n",
    "      IdentityBlock(mi=1024, fm_sizes=[256, 256, 1024]),\n",
    "      IdentityBlock(mi=1024, fm_sizes=[256, 256, 1024]),\n",
    "      IdentityBlock(mi=1024, fm_sizes=[256, 256, 1024]),\n",
    "      IdentityBlock(mi=1024, fm_sizes=[256, 256, 1024]),\n",
    "      # conv block\n",
    "      ConvBlock(mi=1024, fm_sizes=[512, 512, 2048], stride=2),\n",
    "      # identity block x 2\n",
    "      IdentityBlock(mi=2048, fm_sizes=[512, 512, 2048]),\n",
    "      IdentityBlock(mi=2048, fm_sizes=[512, 512, 2048]),\n",
    "      # pool / flatten / dense\n",
    "      AvgPool(ksize=7),\n",
    "      Flatten(),\n",
    "      DenseLayer(mi=2048, mo=1000)\n",
    "    ]\n",
    "    self.input_ = tf.placeholder(tf.float32, shape=(None, 224, 224, 3))\n",
    "    self.output = self.forward(self.input_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet Transfer learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.layers import Input, Lambda, Dense, Flatten\n",
    "from keras.models import Model\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "# from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "\n",
    "# re-size all the images to this\n",
    "IMAGE_SIZE = [224, 224] # feel free to change depending on dataset\n",
    "\n",
    "# training config:\n",
    "epochs = 16\n",
    "batch_size = 32\n",
    "\n",
    "# https://www.kaggle.com/paultimothymooney/blood-cells\n",
    "train_path = '../large_files/blood_cell_images/TRAIN'\n",
    "valid_path = '../large_files/blood_cell_images/TEST'\n",
    "\n",
    "# https://www.kaggle.com/moltean/fruits\n",
    "# train_path = '../large_files/fruits-360/Training'\n",
    "# valid_path = '../large_files/fruits-360/Validation'\n",
    "# train_path = '../large_files/fruits-360-small/Training'\n",
    "# valid_path = '../large_files/fruits-360-small/Validation'\n",
    "\n",
    "# useful for getting number of files\n",
    "image_files = glob(train_path + '/*/*.jp*g')\n",
    "valid_image_files = glob(valid_path + '/*/*.jp*g')\n",
    "\n",
    "# useful for getting number of classes\n",
    "folders = glob(train_path + '/*')\n",
    "\n",
    "\n",
    "# look at an image for fun\n",
    "plt.imshow(image.load_img(np.random.choice(image_files)))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# add preprocessing layer to the front of VGG\n",
    "res = ResNet50(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "\n",
    "# don't train existing weights\n",
    "for layer in res.layers:\n",
    "  layer.trainable = False\n",
    "\n",
    "# our layers - you can add more if you want\n",
    "x = Flatten()(res.output)\n",
    "# x = Dense(1000, activation='relu')(x)\n",
    "prediction = Dense(len(folders), activation='softmax')(x)\n",
    "\n",
    "\n",
    "# create a model object\n",
    "model = Model(inputs=res.input, outputs=prediction)\n",
    "\n",
    "# view the structure of the model\n",
    "model.summary()\n",
    "\n",
    "# tell the model what cost and optimization method to use\n",
    "model.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='rmsprop',\n",
    "  metrics=['accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# create an instance of ImageDataGenerator\n",
    "gen = ImageDataGenerator(\n",
    "  rotation_range=20,\n",
    "  width_shift_range=0.1,\n",
    "  height_shift_range=0.1,\n",
    "  shear_range=0.1,\n",
    "  zoom_range=0.2,\n",
    "  horizontal_flip=True,\n",
    "  vertical_flip=True,\n",
    "  preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "\n",
    "# test generator to see how it works and some other useful things\n",
    "\n",
    "# get label mapping for confusion matrix plot later\n",
    "test_gen = gen.flow_from_directory(valid_path, target_size=IMAGE_SIZE)\n",
    "print(test_gen.class_indices)\n",
    "labels = [None] * len(test_gen.class_indices)\n",
    "for k, v in test_gen.class_indices.items():\n",
    "  labels[v] = k\n",
    "\n",
    "# should be a strangely colored image (due to VGG weights being BGR)\n",
    "for x, y in test_gen:\n",
    "  print(\"min:\", x[0].min(), \"max:\", x[0].max())\n",
    "  plt.title(labels[np.argmax(y[0])])\n",
    "  plt.imshow(x[0])\n",
    "  plt.show()\n",
    "  break\n",
    "\n",
    "\n",
    "# create generators\n",
    "train_generator = gen.flow_from_directory(\n",
    "  train_path,\n",
    "  target_size=IMAGE_SIZE,\n",
    "  shuffle=True,\n",
    "  batch_size=batch_size,\n",
    ")\n",
    "valid_generator = gen.flow_from_directory(\n",
    "  valid_path,\n",
    "  target_size=IMAGE_SIZE,\n",
    "  shuffle=True,\n",
    "  batch_size=batch_size,\n",
    ")\n",
    "\n",
    "\n",
    "# fit the model\n",
    "r = model.fit_generator(\n",
    "  train_generator,\n",
    "  validation_data=valid_generator,\n",
    "  epochs=epochs,\n",
    "  steps_per_epoch=len(image_files) // batch_size,\n",
    "  validation_steps=len(valid_image_files) // batch_size,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "def get_confusion_matrix(data_path, N):\n",
    "  # we need to see the data in the same order\n",
    "  # for both predictions and targets\n",
    "  print(\"Generating confusion matrix\", N)\n",
    "  predictions = []\n",
    "  targets = []\n",
    "  i = 0\n",
    "  for x, y in gen.flow_from_directory(data_path, target_size=IMAGE_SIZE, shuffle=False, batch_size=batch_size * 2):\n",
    "    i += 1\n",
    "    if i % 50 == 0:\n",
    "      print(i)\n",
    "    p = model.predict(x)\n",
    "    p = np.argmax(p, axis=1)\n",
    "    y = np.argmax(y, axis=1)\n",
    "    predictions = np.concatenate((predictions, p))\n",
    "    targets = np.concatenate((targets, y))\n",
    "    if len(targets) >= N:\n",
    "      break\n",
    "\n",
    "  cm = confusion_matrix(targets, predictions)\n",
    "  return cm\n",
    "\n",
    "\n",
    "cm = get_confusion_matrix(train_path, len(image_files))\n",
    "print(cm)\n",
    "valid_cm = get_confusion_matrix(valid_path, len(valid_image_files))\n",
    "print(valid_cm)\n",
    "\n",
    "\n",
    "# plot some data\n",
    "\n",
    "# loss\n",
    "plt.plot(r.history['loss'], label='train loss')\n",
    "plt.plot(r.history['val_loss'], label='val loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# accuracies\n",
    "plt.plot(r.history['acc'], label='train acc')\n",
    "plt.plot(r.history['val_acc'], label='val acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "from util import plot_confusion_matrix\n",
    "plot_confusion_matrix(cm, labels, title='Train confusion matrix')\n",
    "plot_confusion_matrix(valid_cm, labels, title='Validation confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
